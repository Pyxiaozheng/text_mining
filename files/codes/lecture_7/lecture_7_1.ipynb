{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b3a327e-fa1b-4464-b8a4-e1868a8f0ecf",
   "metadata": {},
   "source": [
    "# <center>7. Learning to Classify Text with Python</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c5cca2-67f8-4a49-83e9-9ea2ce31e888",
   "metadata": {},
   "source": [
    "## 1. load the text data and check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1763a1c-7da3-4abd-a702-5ce8349219ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training dtat\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b12e193-cc3f-45c0-a4aa-4f41c54fcb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the size of training data\n",
    "len(twenty_train.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46db1006-d81f-42ef-963f-6d82f5e2aee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class labels of training data\n",
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de619c0b-1cc1-4eed-84a1-35c5cf718f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the size of class labels\n",
    "len(twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "348f42cf-0a15-4d19-b43c-dd31b58a9969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type of training data\n",
    "twenty_train.data.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e30b5b84-a44a-4ee9-a37b-2d6b97e0318c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: irwin@cmptrc.lonestar.org (Irwin Arnstein)\n",
      "Subject: Re: Recommendation on Duc\n",
      "Summary: What's it worth?\n",
      "Distribution: usa\n",
      "Expires: Sat, 1 May 1993 05:00:00 GMT\n",
      "Organization: CompuTrac Inc., Richardson TX\n",
      "Keywords: Ducati, GTS, How much? \n",
      "Lines: 13\n",
      "\n",
      "I have a line on a Ducati 900GTS 1978 model with 17k on the clock.  Runs\n",
      "very well, paint is the bronze/brown/orange faded out, leaks a bit of oil\n",
      "and pops out of 1st with hard accel.  The shop will fix trans and oil \n",
      "leak.  They sold the bike to the 1 and only owner.  They want $3495, and\n",
      "I am thinking more like $3K.  Any opinions out there?  Please email me.\n",
      "Thanks.  It would be a nice stable mate to the Beemer.  Then I'll get\n",
      "a jap bike and call myself Axis Motors!\n",
      "\n",
      "-- \n",
      "-----------------------------------------------------------------------\n",
      "\"Tuba\" (Irwin)      \"I honk therefore I am\"     CompuTrac-Richardson,Tx\n",
      "irwin@cmptrc.lonestar.org    DoD #0826          (R75/6)\n",
      "-----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# investigate what the raw text data in the training data,\n",
    "# e.g., input text of the 10th training sample\n",
    "print(twenty_train.data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0bceb5-243f-4f0f-869d-0b7027bd549e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 rec.motorcycles\n"
     ]
    }
   ],
   "source": [
    "# investigate the label (numerical and textual) of the training data,\n",
    "# e.g., label of the 10th training sample\n",
    "print(twenty_train.target[10],twenty_train.target_names[twenty_train.target[10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d04158-76bd-4bd8-ad72-b565a7c80a4f",
   "metadata": {},
   "source": [
    "## 2. Extract features from raw text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747eac3d-cb5d-4121-844d-0fbf937c7353",
   "metadata": {},
   "source": [
    "Text files are actually series of words (ordered). In order to run machine learning algorithms we need to **convert the text files into numerical feature vectors**. We will be using **bag of words** model for our example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d1d46f-7d20-48d9-8310-c346dfc95152",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img src=\"https://github.com/zhangjianzhang/text_mining/blob/master/files/codes/lecture_7/bow.png?raw=true\">\n",
    "<br>\n",
    "<center><em><strong>Bag of Words</strong></em></center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76f965b7-0f2a-4917-a39c-df746df6d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78506fcb-a8bd-4e3c-8bca-451706f518b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_counts is a Document-Term matrix and its shape is [n_samples, n_features].\n",
    "# i.e., there are 11314 training samples and 130107 words in the vocabulary\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325ac45-ddfa-4d9b-8049-cdc2b89801d8",
   "metadata": {},
   "source": [
    "Let's examine the content of the `X_train_counts` and investigate what does it means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cfde55e-5c49-41d3-a6c7-276d3d3f7c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a9b251d-9ef4-4de1-a334-bc907e360294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x130107 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 109 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.getrow(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03af6344-b4c7-421c-9bda-7c2cd5230311",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = X_train_counts.getrow(10).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f78dea7-b290-4f73-bd68-d6882c979fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "504025fc-e89d-4699-818b-0d450b4711cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([     0,   1049,   1410,   3802,   5791,   6437,   6475,   8042,\n",
       "         11976,  12963,  21480,  25568,  27721,  28146,  28601,  29451,\n",
       "         30868,  32311,  32489,  33301,  33527,  35151,  35194,  37423,\n",
       "         40477,  40647,  41633,  47982,  48421,  49328,  49331,  51268,\n",
       "         53441,  54163,  55597,  56979,  58830,  59534,  60731,  61959,\n",
       "         62221,  63910,  64186,  66670,  68524,  68532,  68766,  69511,\n",
       "         72384,  75028,  75033,  75901,  76007,  76032,  76377,  76681,\n",
       "         79785,  80005,  80638,  83256,  83706,  83914,  84681,  85447,\n",
       "         87170,  89362,  89550,  89860,  89919,  90097,  90266,  90364,\n",
       "         90379,  90774,  91192,  91722,  94362,  94986,  98828,  99721,\n",
       "        100059, 101898, 103528, 104702, 106965, 108718, 110130, 111322,\n",
       "        111695, 114428, 114455, 114520, 114579, 114586, 114646, 114702,\n",
       "        115475, 116139, 116882, 117230, 119714, 121265, 123196, 123759,\n",
       "        123984, 124332, 124616, 125095, 125110]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acdfc591-e51b-46e7-9386-d31f769e1567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24ed5ceb-1312-49ec-b28a-c85d3c8841cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130107"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are 130107 words in the vocabulary in total\n",
    "len(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d93f246f-a54d-40f6-bb57-0285407420f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the word \"good\" is in the vocabulary\n",
    "'good' in count_vect.vocabulary_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38dca3a6-48fb-462d-a5a1-3042a82c56df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59779"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us find the value of \"good\", i.e., the numerical id of \"good\"\n",
    "count_vect.vocabulary_['good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "980070a2-e7a6-41fe-b60d-38bf1adb8bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v:k for k,v in count_vect.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42b15d1c-7c10-4668-84af-cd629576f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for idx in arr.nonzero()[1]:\n",
    "    word = idx2word.get(idx)\n",
    "    word_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3bc1c2e-185f-41dc-bcca-a9fce0abffbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '05', '0826', '13', '17k', '1978', '1993', '1st', '3495', '3k', '900gts', 'accel', 'am', 'and', 'any', 'arnstein', 'axis', 'be', 'beemer', 'bike', 'bit', 'bronze', 'brown', 'call', 'clock', 'cmptrc', 'computrac', 'distribution', 'dod', 'duc', 'ducati', 'email', 'expires', 'faded', 'fix', 'from', 'get', 'gmt', 'gts', 'hard', 'have', 'honk', 'how', 'inc', 'irwin', 'is', 'it', 'jap', 'keywords', 'leak', 'leaks', 'like', 'line', 'lines', 'll', 'lonestar', 'mate', 'may', 'me', 'model', 'more', 'motors', 'much', 'myself', 'nice', 'of', 'oil', 'on', 'only', 'opinions', 'orange', 'org', 'organization', 'out', 'owner', 'paint', 'please', 'pops', 'r75', 're', 'recommendation', 'richardson', 'runs', 'sat', 'shop', 'sold', 'stable', 'subject', 'summary', 'thanks', 'the', 'then', 'there', 'therefore', 'they', 'thinking', 'to', 'trans', 'tuba', 'tx', 'usa', 'very', 'want', 'well', 'what', 'will', 'with', 'worth', 'would']\n"
     ]
    }
   ],
   "source": [
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b807023-71cc-4fb5-be45-1bd0ee183a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: irwin@cmptrc.lonestar.org (Irwin Arnstein)\n",
      "Subject: Re: Recommendation on Duc\n",
      "Summary: What's it worth?\n",
      "Distribution: usa\n",
      "Expires: Sat, 1 May 1993 05:00:00 GMT\n",
      "Organization: CompuTrac Inc., Richardson TX\n",
      "Keywords: Ducati, GTS, How much? \n",
      "Lines: 13\n",
      "\n",
      "I have a line on a Ducati 900GTS 1978 model with 17k on the clock.  Runs\n",
      "very well, paint is the bronze/brown/orange faded out, leaks a bit of oil\n",
      "and pops out of 1st with hard accel.  The shop will fix trans and oil \n",
      "leak.  They sold the bike to the 1 and only owner.  They want $3495, and\n",
      "I am thinking more like $3K.  Any opinions out there?  Please email me.\n",
      "Thanks.  It would be a nice stable mate to the Beemer.  Then I'll get\n",
      "a jap bike and call myself Axis Motors!\n",
      "\n",
      "-- \n",
      "-----------------------------------------------------------------------\n",
      "\"Tuba\" (Irwin)      \"I honk therefore I am\"     CompuTrac-Richardson,Tx\n",
      "irwin@cmptrc.lonestar.org    DoD #0826          (R75/6)\n",
      "-----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dea39807-6888-4133-a33d-e79cc9490688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f4e6e14-68d8-44c9-8c89-729a8ac60817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"00\" occurs 2 times in the 10th training sample\n",
    "X_train_counts[10,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96d6b8c-cbf2-4f54-9b50-eaf4b4d60859",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img src=\"https://github.com/zhangjianzhang/text_mining/blob/master/files/codes/lecture_7/tfidf.png?raw=true\">\n",
    "<br>\n",
    "<center><em><strong>Term Frequency-Inverse Document Frequency</strong></em></center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d44e94ab-94b9-47b5-9625-34bef3826da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10a016b3-eaf7-4aa7-ae4a-4ee9edc6f47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_tfidf is a document-tfidf matrix\n",
    "# its shape is the same as the shape of the above document-count matrix\n",
    "# i.e., [n_samples, n_features]\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d6b37d-6be6-44d0-86a3-4aa741c04ae3",
   "metadata": {},
   "source": [
    "## 3. Train text classfiers with different ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72ffe3f8-bead-44ad-9121-aaa5bbc48090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_counts, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f285e897-b7ff-42c1-a912-ef0e57951c6c",
   "metadata": {},
   "source": [
    "Building a pipeline: We can write less code and do all of the above, by building a pipeline as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4f4061a-ba2a-4b96-af7f-1cca80c703ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    "                    ])\n",
    "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c07795d7-6c41-4536-829b-fe3eda61234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "predicted = text_clf.predict(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cff426f1-e703-43b9-babe-0706541ad32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7738980350504514"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the accuracy is about 77.39%\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d69c970-78e8-4988-ba66-5d44ce0180e5",
   "metadata": {},
   "source": [
    "Let’s try using a different algorithm **SVM**, and see if we can get any better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "587dd261-a196-497c-a420-f7f39dd03462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "246fe828-341b-4294-986c-813f731707bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge',\n",
    "                                                   penalty='l2',\n",
    "                                                   alpha=1e-3,\n",
    "                                                   n_iter_no_change=5,\n",
    "                                                   random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d53a0ee-ab52-4a1f-9c1e-2ab483798441",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = text_clf_svm.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d47371d-2dc3-45bd-9abc-9fcc77228cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_svm = text_clf_svm.predict(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34b9c2eb-7577-4127-b353-5101eff58ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8240839086563994"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 82.41%\n",
    "np.mean(predicted_svm == twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178c0018-ff79-4345-be60-f2727ab45e7d",
   "metadata": {},
   "source": [
    "## 4. Grid Search for Selecting the Best Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b0656-94ce-403b-9498-4e1e1afb1266",
   "metadata": {},
   "source": [
    "Almost all the classifiers will have various parameters which can be tuned to obtain optimal performance. \n",
    "\n",
    "Scikit-learn gives an extremely useful tool `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "229bf131-7aac-4c06-ade0-8ee6dacf7727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34ec27ae-486a-46d5-97f8-fcf9184437dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "               'clf__alpha': (1e-2, 1e-3),\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea05ad4-5339-4e2f-a2a5-57c090e29e1b",
   "metadata": {},
   "source": [
    "Here, we are creating a list of parameters for which we would like to do performance tuning. \n",
    "\n",
    "All the parameters name start with the component name (remember the component name we gave previously). E.g. `vect__ngram_range`; here we are telling to use unigram and bigrams and choose the one which is optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a996f69-5317-4b90-a161-c806e4e69060",
   "metadata": {},
   "source": [
    "Next, we create an instance of the grid search by passing the classifier, parameters and `n_jobs=-1` which tells to use multiple cores from user machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb7855c5-0627-4947-ab86-c8b1b00a58b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff618252-f345-42b7-9033-94e47e69b8a5",
   "metadata": {},
   "source": [
    "This might take few minutes to run depending on the machine configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aa3ef1-8890-4d0f-82b8-2d2ca125ba41",
   "metadata": {},
   "source": [
    "Lastly, to see the best mean score and the params, run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ef627d4-7b3d-44e3-b5d5-3ad96f549059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9157684864695698"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy is improved to 91.58%\n",
    "gs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f57f49d4-cc28-4e29-974d-e36b946bf3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the best parameter is as follow:\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34b581b-c302-4453-b7a6-f7e1e1b23184",
   "metadata": {},
   "source": [
    "Let's tuning the SVM classifier with grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f76de22-d870-45c3-8404-3a98b0a807cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                  'tfidf__use_idf': (True, False),\n",
    "                  'clf-svm__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "33b2847c-074b-4535-b5a7-dc5ac2222ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9051618841994754"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the accuracy is improved to 90.52%\n",
    "gs_clf_svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e31603e-4708-41cd-9829-2b1ca4144912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf-svm__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6582593e-1b54-4f98-aeb3-b6ace6c4b8ab",
   "metadata": {},
   "source": [
    "You can further optimize the SVM classifier by tuning other parameters. This is left up to you to explore more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10897df-5c97-4fc6-b7ff-3545dba62c4d",
   "metadata": {},
   "source": [
    "## 5. Some Useful Tips for Improving the Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9caaa8-bfd9-4688-930d-c05b8a5d9716",
   "metadata": {},
   "source": [
    "**Removing stop words**: (the, then etc) from the data. \n",
    "\n",
    "You should do this only when stop words are not useful for the underlying problem. \n",
    "\n",
    "In most of the text classification problems, this is indeed not useful. \n",
    "\n",
    "Let’s see if removing stop words increases the accuracy. Update the code for creating object of `CountVectorizer` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7b0be66-0a7d-432c-9de0-10541c3af34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c634acd-3631-42a4-aa68-04ba66a81a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f8ab12a-38ce-4a0e-8d15-f56070560a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8169144981412639"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after stopwords removal, the accuracy is boosted from 77.39% to 81.69%\n",
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f8ef5e-c6d5-4c04-9fec-c8a4715553ed",
   "metadata": {},
   "source": [
    "**FitPrior=False**: When set to `false` for MultinomialNB, a uniform prior will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d29da901-7bf9-406b-8cc5-ac7f460b3681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8214285714285714"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 81.69 -> 82.14, improve a little\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB(fit_prior=False)),\n",
    "                    ])\n",
    "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e94b81-66e9-45aa-8199-886b52cc6ec6",
   "metadata": {},
   "source": [
    "**Stemming**: stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form. E.g. A stemming algorithm reduces the words *fishing*, *fished*, and *fisher* to the root word, *fish*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383f70f8-96a4-44e5-9914-f117ff93ca1e",
   "metadata": {},
   "source": [
    "Below we use `Snowball stemmer` which works very well for English language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea2f3705-7165-4f38-9e27-30669601c856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8167817312798725"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "    \n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
    "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect),\n",
    "                             ('tfidf', TfidfTransformer()),\n",
    "                             ('mnb', MultinomialNB(fit_prior=False)),\n",
    "                            ])\n",
    "\n",
    "# 82.14 -> 81.68 decrease a little \n",
    "text_mnb_stemmed = text_mnb_stemmed.fit(twenty_train.data, twenty_train.target)\n",
    "predicted_mnb_stemmed = text_mnb_stemmed.predict(twenty_test.data)\n",
    "np.mean(predicted_mnb_stemmed == twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2f3043-792c-4cc2-8c1a-5fb87bf54b63",
   "metadata": {},
   "source": [
    "Try wordnet lemmatizer in `NLTK` by yourself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
