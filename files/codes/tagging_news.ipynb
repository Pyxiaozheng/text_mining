{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e399f35-917a-4b85-8c10-65d376f6b93a",
   "metadata": {},
   "source": [
    "<center><font size=4 style=\"color:#BA4A00\"><strong>预处理中文新闻分类语料</strong></font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ef689a-d8a5-4415-8f41-5c4c1aacd972",
   "metadata": {},
   "source": [
    "数据格式为：\n",
    "\n",
    "- `cn_news`为中文新闻原始语料，每个文件夹包含一个类别的新闻，每个txt文件为一条新闻，txt文件中段落分隔符为空行；\n",
    "- `cn_news_tagged`为新闻语料标注结果，结构同原始语料，txt文件中每行为一个句子的标注结果，段落分隔符为空行；\n",
    "\n",
    "\n",
    "主要预处理步骤为：\n",
    "\n",
    "- 去除空白字符；\n",
    "- 使用spacy对新闻文本进行分句、分词、词性标注；\n",
    "- spacy用法-https://spacy.io/models/zh\n",
    "- TODO: 根据token字形，去除标点，去除notprintable字符"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0c3c70-6e4c-4e25-9806-3bc2fc33c902",
   "metadata": {},
   "source": [
    "<center><font size=2.5>spaCy粗粒度词性标签列表</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22feeb79-7c21-4aa6-9f84-cec980419182",
   "metadata": {},
   "source": [
    "<table style=\"height:625px\" width=\"699\"><tbody><tr><th>POS</th><th>DESCRIPTION</th><th>EXAMPLES</th></tr><tr><td>ADJ</td><td>adjective</td><td>*big, old, green, incomprehensible, first*</td></tr><tr><td>ADP</td><td>adposition</td><td>*in, to, during*</td></tr><tr><td>ADV</td><td>adverb</td><td>*very, tomorrow, down, where, there*</td></tr><tr><td>AUX</td><td>auxiliary</td><td>*is, has (done), will (do), should (do)*</td></tr><tr><td>CONJ</td><td>conjunction</td><td>*and, or, but*</td></tr><tr><td>CCONJ</td><td>coordinating conjunction</td><td>*and, or, but*</td></tr><tr><td>DET</td><td>determiner</td><td>*a, an, the*</td></tr><tr><td>INTJ</td><td>interjection</td><td>*psst, ouch, bravo, hello*</td></tr><tr><td>NOUN</td><td>noun</td><td>*girl, cat, tree, air, beauty*</td></tr><tr><td>NUM</td><td>numeral</td><td>*1, 2017, one, seventy-seven, IV, MMXIV*</td></tr><tr><td>PART</td><td>particle</td><td>*’s, not,*</td></tr><tr><td>PRON</td><td>pronoun</td><td>*I, you, he, she, myself, themselves, somebody*</td></tr><tr><td>PROPN</td><td>proper noun</td><td>*Mary, John, London, NATO, HBO*</td></tr><tr><td>PUNCT</td><td>punctuation</td><td>*., (, ), ?*</td></tr><tr><td>SCONJ</td><td>subordinating conjunction</td><td>*if, while, that*</td></tr><tr><td>SYM</td><td>symbol</td><td>*$, %, §, ©, +, −, ×, ÷, =, :), emoji*</td></tr><tr><td>VERB</td><td>verb</td><td>*run, runs, running, eat, ate, eating*</td></tr><tr><td>X</td><td>other</td><td>*sfpksdpsxmsa*</td></tr><tr><td>SPACE</td><td>space</td></tr></tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77122532-87e5-4e9d-8684-f5264ba093c2",
   "metadata": {},
   "source": [
    "spaCy细粒度词性标签含义：\n",
    " - https://machinelearningknowledge.ai/tutorial-on-spacy-part-of-speech-pos-tagging/#Spacy_POS_Tags_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d549bd-4ca4-4b9f-acd3-6e661120b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import html\n",
    "from spacy.lang.zh.examples import sentences \n",
    "\n",
    "nlp = spacy.load(\"zh_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67740fcd-c1a3-4e80-ab77-3f5647198470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagging(text):\n",
    "    f_list = []\n",
    "    paragraphs = html.unescape(text).strip().split('\\n')\n",
    "    for paragraph in paragraphs:\n",
    "        if paragraph.strip():\n",
    "            p_list = []\n",
    "            doc = nlp(paragraph.strip())\n",
    "            for sent in doc.sents:\n",
    "                t_list = []\n",
    "                for token in sent:\n",
    "                    t_list.append(token.text+'/'+token.pos_)\n",
    "                p_list.append(' '.join(t_list))\n",
    "            f_list.append('\\n'.join(p_list))\n",
    "    tagged_text = '\\n\\n'.join(f_list)\n",
    "    return tagged_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50933b1-7492-43f0-b917-ab0473ab5033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "raw_data_dir = './cn_news/'\n",
    "tagged_data_dir = './cn_news_tagged/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ab309e6-24de-4d88-859e-e43649db1cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = os.listdir(raw_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b45cebe-8e82-4e06-aa43-78ea5b81a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    files = os.listdir(raw_data_dir + category)\n",
    "    for file in files:\n",
    "        file_path = raw_data_dir + category + '/' + file\n",
    "        if not os.path.exists(tagged_data_dir + category):\n",
    "            os.mkdir(tagged_data_dir + category)\n",
    "        new_file_path = tagged_data_dir + category + '/' + file\n",
    "        with open(file_path, encoding='gbk',errors='ignore') as f:\n",
    "            raw_text = f.read()\n",
    "        tagged_text = tagging(raw_text)\n",
    "        with open(new_file_path,'w') as f:\n",
    "            f.write(tagged_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
