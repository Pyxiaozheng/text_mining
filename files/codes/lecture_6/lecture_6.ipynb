{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf88c4e",
   "metadata": {},
   "source": [
    "# <center>6. Learning to Classify Text</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457957b1",
   "metadata": {},
   "source": [
    "# 1.   Supervised Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27602cee",
   "metadata": {},
   "source": [
    "**Classification** is the task of choosing the correct class label for a given input.\n",
    "\n",
    "In basic classification tasks, **each input** is considered **in isolation** from all other inputs, and the set of **labels is defined in advance**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f8b5a",
   "metadata": {},
   "source": [
    "- Deciding whether an email is spam or not; (二分类)\n",
    "\n",
    "- Deciding what the topic of a news article is, from a fixed list of topic areas such as \"sports,\" \"technology,\" and \"politics.\"; (多标签分类)\n",
    "\n",
    "- Deciding whether a given occurrence of the word *bank* is used to refer to a river bank, a financial institution, the act of tilting to the side, or the act of depositing something in a financial institution (河岸，金融机构，侧身的动作，将某物存入金融机构的动作). (词义消歧)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58f73ef",
   "metadata": {},
   "source": [
    "The basic classification task has a number of **interesting variants**. \n",
    "\n",
    "- In multi-class classification, each instance may be assigned multiple labels; \n",
    "\n",
    "- In open-class classification, the set of labels is not defined in advance; \n",
    "\n",
    "- In sequence classification, a list of inputs are jointly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8d8dff",
   "metadata": {},
   "source": [
    "A classifier is called **supervised** if it is built based on training corpora containing the correct label for each input. \n",
    "\n",
    "The framework used by supervised classification is shown in below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0baa38a",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img src=\"https://www.nltk.org/images/supervised-classification.png\">\n",
    "<br>\n",
    "<center><em><strong>Supervised Classification Framework</strong></em></center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d232ab",
   "metadata": {},
   "source": [
    "## 1.1   Gender Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca25af3",
   "metadata": {},
   "source": [
    "In Chapter 2, we saw that male and female names have some **distinctive characteristics**. \n",
    "\n",
    "Names ending in *a*, *e* and *i* are likely to be female, while names ending in *k*, *o*, *r*, *s* and *t* are likely to be male. \n",
    "\n",
    "Let's build a classifier to model these differences more precisely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597392a1",
   "metadata": {},
   "source": [
    "The **first step** in creating a classifier is deciding what **features** of the input are **relevant**, and how to **encode those features**. \n",
    "\n",
    "For this example, we'll start by just **looking at the final letter of a given name**.\n",
    "\n",
    "The following feature extractor function builds a dictionary containing relevant information about a given name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ebb373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c4dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62345e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'k'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features('Shrek')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b06ca8",
   "metadata": {},
   "source": [
    "The returned dictionary, known as **a feature set**, maps from feature names to their values. \n",
    "\n",
    "**Feature names** are case-sensitive strings that typically provide a short **human-readable** description of the feature.\n",
    "\n",
    "**Feature values** are values with **simple types**, such as booleans, numbers, and strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61132bb",
   "metadata": {},
   "source": [
    "Now that we've defined a feature extractor, we need to prepare a list of examples and corresponding class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb3a9e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f77c360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] \n",
    "                 + [(name, 'female') for name in names.words('female.txt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02f4dcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d22d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7944"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c848d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Aamir', 'male'),\n",
       " ('Aaron', 'male'),\n",
       " ('Abbey', 'male'),\n",
       " ('Abbie', 'male'),\n",
       " ('Abbot', 'male')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dc7c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 将标注数据随机打乱\n",
    "random.seed(10)\n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7edbd9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Gabrila', 'female'),\n",
       " ('Rosario', 'female'),\n",
       " ('Annabella', 'female'),\n",
       " ('Mead', 'female'),\n",
       " ('Pepe', 'male')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be4ab1c",
   "metadata": {},
   "source": [
    "Next, we use the feature extractor to process the names data, and divide the resulting list of feature sets into a **training set** and a **test set**.\n",
    "\n",
    "The training set is used to train a new \"naive Bayes\" classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "189fbdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "157d4e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'last_letter': 'a'}, 'female'),\n",
       " ({'last_letter': 'o'}, 'female'),\n",
       " ({'last_letter': 'a'}, 'female'),\n",
       " ({'last_letter': 'd'}, 'female'),\n",
       " ({'last_letter': 'e'}, 'male'),\n",
       " ({'last_letter': 'a'}, 'female'),\n",
       " ({'last_letter': 'i'}, 'female'),\n",
       " ({'last_letter': 'e'}, 'female'),\n",
       " ({'last_letter': 'a'}, 'female'),\n",
       " ({'last_letter': 'e'}, 'female')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a660d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a387320",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b98da35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Neo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92a1cabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Trinity'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a3e45b",
   "metadata": {},
   "source": [
    "We can **systematically evaluate the classifier** on a much larger quantity of unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b99300f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a3831d",
   "metadata": {},
   "source": [
    "**Finally**, we can examine the classifier to determine **which features** it found **most effective** for distinguishing the names' genders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c7b8e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     35.6 : 1.0\n",
      "             last_letter = 'k'              male : female =     32.9 : 1.0\n",
      "             last_letter = 'f'              male : female =     15.4 : 1.0\n",
      "             last_letter = 'p'              male : female =     12.6 : 1.0\n",
      "             last_letter = 'v'              male : female =     11.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403f888a",
   "metadata": {},
   "source": [
    "These ratios are known as **likelihood ratios**, and can be useful for **comparing different feature-outcome relationships**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19b0726",
   "metadata": {},
   "source": [
    "**Your Turn**: \n",
    "\n",
    "Modify the `gender_features()` function to provide the classifier with features encoding the length of the name, its first letter, and any other features that seem like they might be informative. Retrain the classifier with these new features, and test its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a321c5a",
   "metadata": {},
   "source": [
    "When working with **large corpora**, constructing a single list that contains the features of every instance can use up **a large amount of memory**.\n",
    "\n",
    "In these cases, use the function `nltk.classify.apply_features`, which returns an object that acts **like a list but does not store all the feature sets in memory**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5ad0755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import apply_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d1efb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = apply_features(gender_features, labeled_names[500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "709b6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = apply_features(gender_features, labeled_names[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb5360b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.collections.LazyMap"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f470e399",
   "metadata": {},
   "source": [
    "## 1.2   Choosing The Right Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f867595c",
   "metadata": {},
   "source": [
    "**Selecting relevant features** and deciding how to **encode them** for a learning method can have **an enormous impact** on the learning **method's ability** to extract a good model. \n",
    "\n",
    "Although it's often possible to **get decent performance** by using **a fairly simple and obvious set of features**, there are usually **significant gains** to be had by using **carefully constructed features based on a thorough understanding of the task** at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3590e3",
   "metadata": {},
   "source": [
    "Typically, feature extractors are built through a process of **trial-and-error**, guided by **intuitions** about what information is relevant to the problem. \n",
    "\n",
    "It's common to start with a **\"kitchen sink\"** approach (水槽法), **including all the features** that you can think of, and **then checking** to see which features actually are helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46cbc3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    # 首字母\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    # 尾字母\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        # a-z计数\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        # 是否包含a-z\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80f7d28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_letter': 'j',\n",
       " 'last_letter': 'n',\n",
       " 'count(a)': 0,\n",
       " 'has(a)': False,\n",
       " 'count(b)': 0,\n",
       " 'has(b)': False,\n",
       " 'count(c)': 0,\n",
       " 'has(c)': False,\n",
       " 'count(d)': 0,\n",
       " 'has(d)': False,\n",
       " 'count(e)': 0,\n",
       " 'has(e)': False,\n",
       " 'count(f)': 0,\n",
       " 'has(f)': False,\n",
       " 'count(g)': 0,\n",
       " 'has(g)': False,\n",
       " 'count(h)': 1,\n",
       " 'has(h)': True,\n",
       " 'count(i)': 0,\n",
       " 'has(i)': False,\n",
       " 'count(j)': 1,\n",
       " 'has(j)': True,\n",
       " 'count(k)': 0,\n",
       " 'has(k)': False,\n",
       " 'count(l)': 0,\n",
       " 'has(l)': False,\n",
       " 'count(m)': 0,\n",
       " 'has(m)': False,\n",
       " 'count(n)': 1,\n",
       " 'has(n)': True,\n",
       " 'count(o)': 1,\n",
       " 'has(o)': True,\n",
       " 'count(p)': 0,\n",
       " 'has(p)': False,\n",
       " 'count(q)': 0,\n",
       " 'has(q)': False,\n",
       " 'count(r)': 0,\n",
       " 'has(r)': False,\n",
       " 'count(s)': 0,\n",
       " 'has(s)': False,\n",
       " 'count(t)': 0,\n",
       " 'has(t)': False,\n",
       " 'count(u)': 0,\n",
       " 'has(u)': False,\n",
       " 'count(v)': 0,\n",
       " 'has(v)': False,\n",
       " 'count(w)': 0,\n",
       " 'has(w)': False,\n",
       " 'count(x)': 0,\n",
       " 'has(x)': False,\n",
       " 'count(y)': 0,\n",
       " 'has(y)': False,\n",
       " 'count(z)': 0,\n",
       " 'has(z)': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features2('John') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a32bbc",
   "metadata": {},
   "source": [
    "However, there are usually **limits to the number of features** that you should use with a given learning algorithm.\n",
    "\n",
    "If you provide **too many features**, then the algorithm will have a higher chance of relying on idiosyncrasies of your training data that don't generalize well to new examples. \n",
    "如果提供了太多特征，算法将更有可能依赖训练数据的特质，这些特质不能很好地推广到新示例。\n",
    "\n",
    "This problem is known as **overfitting**, and can be especially problematic when working with **small training sets**. \n",
    "\n",
    "For example, if we train a naive Bayes classifier using the above feature extractor `gender_features2`, it will overfit the relatively small training set, resulting in a system whose accuracy is **about 1% lower** than the accuracy of a classifier that **only pays attention to the final letter of each name**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b503775b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.756\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(gender_features2(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b4363a",
   "metadata": {},
   "source": [
    "Once **an initial set of features** has been chosen, a very productive method for **refining the feature set** is **error analysis**. \n",
    "\n",
    "First, we select a **development set**, containing the corpus **data for creating the model**.\n",
    "\n",
    "This development set is then subdivided into the **training set** and the **dev-test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3393b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = labeled_names[1500:]\n",
    "devtest_names = labeled_names[500:1500]\n",
    "test_names = labeled_names[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2723c4e9",
   "metadata": {},
   "source": [
    "The training set is used to **train the model**;\n",
    "\n",
    "The dev-test set is used to perform **error analysis**;\n",
    "\n",
    "The test set serves in our **final evaluation of the system**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46d61fb",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img src=\"https://www.nltk.org/images/corpus-org.png\">\n",
    "<br>\n",
    "<center><em><strong>Organization of corpus data for training supervised classifiers</strong></em></center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4918152",
   "metadata": {},
   "source": [
    "Having divided the corpus into appropriate datasets, we train a model using the training set, and then run it on the dev-test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2282a1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.763\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
    "test_set = [(gender_features(n), gender) for (n, gender) in test_names]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43db5b0",
   "metadata": {},
   "source": [
    "Using the dev-test set, we can generate a list of the errors that the classifier makes when predicting name genders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba6dd83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier.classify(gender_features(name))\n",
    "    if guess != tag:\n",
    "        errors.append((tag, guess, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23f9b007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f6b4e3",
   "metadata": {},
   "source": [
    "Then examine individual error cases where the model predicted the wrong label;\n",
    "\n",
    "The feature set can then be adjusted accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe7d31e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=female   guess=male     name=Aeriell                       \n",
      "correct=female   guess=male     name=Alisun                        \n",
      "correct=female   guess=male     name=Allsun                        \n",
      "correct=female   guess=male     name=Allyn                         \n",
      "correct=female   guess=male     name=Amabel                        \n",
      "correct=female   guess=male     name=Amargo                        \n",
      "correct=female   guess=male     name=Beilul                        \n",
      "correct=female   guess=male     name=Bird                          \n",
      "correct=female   guess=male     name=Blair                         \n",
      "correct=female   guess=male     name=Britt                         \n",
      "correct=female   guess=male     name=Cam                           \n",
      "correct=female   guess=male     name=Caril                         \n",
      "correct=female   guess=male     name=Carilyn                       \n",
      "correct=female   guess=male     name=Carin                         \n",
      "correct=female   guess=male     name=Carleen                       \n",
      "correct=female   guess=male     name=Caro                          \n",
      "correct=female   guess=male     name=Carolann                      \n",
      "correct=female   guess=male     name=Cathleen                      \n",
      "correct=female   guess=male     name=Cathryn                       \n",
      "correct=female   guess=male     name=Chad                          \n",
      "correct=female   guess=male     name=Charin                        \n",
      "correct=female   guess=male     name=Cherilynn                     \n",
      "correct=female   guess=male     name=Cherin                        \n",
      "correct=female   guess=male     name=Chloris                       \n",
      "correct=female   guess=male     name=Christal                      \n",
      "correct=female   guess=male     name=Cinnamon                      \n",
      "correct=female   guess=male     name=Clio                          \n",
      "correct=female   guess=male     name=Coleen                        \n",
      "correct=female   guess=male     name=Coral                         \n",
      "correct=female   guess=male     name=Coreen                        \n",
      "correct=female   guess=male     name=Coriss                        \n",
      "correct=female   guess=male     name=Cris                          \n",
      "correct=female   guess=male     name=Dallas                        \n",
      "correct=female   guess=male     name=Deeann                        \n",
      "correct=female   guess=male     name=Demetris                      \n",
      "correct=female   guess=male     name=Doro                          \n",
      "correct=female   guess=male     name=Drew                          \n",
      "correct=female   guess=male     name=Eden                          \n",
      "correct=female   guess=male     name=Eilis                         \n",
      "correct=female   guess=male     name=Emlyn                         \n",
      "correct=female   guess=male     name=Emmalyn                       \n",
      "correct=female   guess=male     name=Erinn                         \n",
      "correct=female   guess=male     name=Esther                        \n",
      "correct=female   guess=male     name=Farand                        \n",
      "correct=female   guess=male     name=Faun                          \n",
      "correct=female   guess=male     name=Frank                         \n",
      "correct=female   guess=male     name=Gael                          \n",
      "correct=female   guess=male     name=Gennifer                      \n",
      "correct=female   guess=male     name=Gill                          \n",
      "correct=female   guess=male     name=Glad                          \n",
      "correct=female   guess=male     name=Glen                          \n",
      "correct=female   guess=male     name=Gretchen                      \n",
      "correct=female   guess=male     name=Harriott                      \n",
      "correct=female   guess=male     name=Heather                       \n",
      "correct=female   guess=male     name=Ines                          \n",
      "correct=female   guess=male     name=Isabeau                       \n",
      "correct=female   guess=male     name=Isabel                        \n",
      "correct=female   guess=male     name=Izabel                        \n",
      "correct=female   guess=male     name=Jackquelin                    \n",
      "correct=female   guess=male     name=Jaclin                        \n",
      "correct=female   guess=male     name=Jacquelyn                     \n",
      "correct=female   guess=male     name=Janean                        \n",
      "correct=female   guess=male     name=Janeen                        \n",
      "correct=female   guess=male     name=Janel                         \n",
      "correct=female   guess=male     name=Jo Ann                        \n",
      "correct=female   guess=male     name=Jo-Ann                        \n",
      "correct=female   guess=male     name=Joan                          \n",
      "correct=female   guess=male     name=Joellyn                       \n",
      "correct=female   guess=male     name=Joselyn                       \n",
      "correct=female   guess=male     name=Jourdan                       \n",
      "correct=female   guess=male     name=Karilynn                      \n",
      "correct=female   guess=male     name=Karin                         \n",
      "correct=female   guess=male     name=Karlen                        \n",
      "correct=female   guess=male     name=Kaster                        \n",
      "correct=female   guess=male     name=Kathleen                      \n",
      "correct=female   guess=male     name=Kathlin                       \n",
      "correct=female   guess=male     name=Katleen                       \n",
      "correct=female   guess=male     name=Kaylil                        \n",
      "correct=female   guess=male     name=Keren                         \n",
      "correct=female   guess=male     name=Kip                           \n",
      "correct=female   guess=male     name=Kit                           \n",
      "correct=female   guess=male     name=Kristen                       \n",
      "correct=female   guess=male     name=Leann                         \n",
      "correct=female   guess=male     name=Lilian                        \n",
      "correct=female   guess=male     name=Loreen                        \n",
      "correct=female   guess=male     name=Lou                           \n",
      "correct=female   guess=male     name=Lyn                           \n",
      "correct=female   guess=male     name=Mab                           \n",
      "correct=female   guess=male     name=Madlin                        \n",
      "correct=female   guess=male     name=Margalit                      \n",
      "correct=female   guess=male     name=Margeaux                      \n",
      "correct=female   guess=male     name=Margit                        \n",
      "correct=female   guess=male     name=Margo                         \n",
      "correct=female   guess=male     name=Mariellen                     \n",
      "correct=female   guess=male     name=Marillin                      \n",
      "correct=female   guess=male     name=Maryjo                        \n",
      "correct=female   guess=male     name=Marylin                       \n",
      "correct=female   guess=male     name=Marys                         \n",
      "correct=female   guess=male     name=Meghann                       \n",
      "correct=female   guess=male     name=Mehetabel                     \n",
      "correct=female   guess=male     name=Melisent                      \n",
      "correct=female   guess=male     name=Morgan                        \n",
      "correct=female   guess=male     name=Nichol                        \n",
      "correct=female   guess=male     name=Nitin                         \n",
      "correct=female   guess=male     name=Noellyn                       \n",
      "correct=female   guess=male     name=Pearl                         \n",
      "correct=female   guess=male     name=Phylis                        \n",
      "correct=female   guess=male     name=Pris                          \n",
      "correct=female   guess=male     name=Rakel                         \n",
      "correct=female   guess=male     name=Rochell                       \n",
      "correct=female   guess=male     name=Ros                           \n",
      "correct=female   guess=male     name=Roz                           \n",
      "correct=female   guess=male     name=Scarlett                      \n",
      "correct=female   guess=male     name=Sharl                         \n",
      "correct=female   guess=male     name=Sharon                        \n",
      "correct=female   guess=male     name=Shaylyn                       \n",
      "correct=female   guess=male     name=Sheilakathryn                 \n",
      "correct=female   guess=male     name=Shell                         \n",
      "correct=female   guess=male     name=Sibeal                        \n",
      "correct=female   guess=male     name=Stoddard                      \n",
      "correct=female   guess=male     name=Sybil                         \n",
      "correct=female   guess=male     name=Sydel                         \n",
      "correct=female   guess=male     name=Thomasin                      \n",
      "correct=female   guess=male     name=Yoko                          \n",
      "correct=male     guess=female   name=Andrey                        \n",
      "correct=male     guess=female   name=Andy                          \n",
      "correct=male     guess=female   name=Arnie                         \n",
      "correct=male     guess=female   name=Arvy                          \n",
      "correct=male     guess=female   name=Barclay                       \n",
      "correct=male     guess=female   name=Barny                         \n",
      "correct=male     guess=female   name=Bay                           \n",
      "correct=male     guess=female   name=Brody                         \n",
      "correct=male     guess=female   name=Bucky                         \n",
      "correct=male     guess=female   name=Butch                         \n",
      "correct=male     guess=female   name=Carleigh                      \n",
      "correct=male     guess=female   name=Chaunce                       \n",
      "correct=male     guess=female   name=Chrisy                        \n",
      "correct=male     guess=female   name=Clemente                      \n",
      "correct=male     guess=female   name=Cobbie                        \n",
      "correct=male     guess=female   name=Corky                         \n",
      "correct=male     guess=female   name=Cyrille                       \n",
      "correct=male     guess=female   name=Dane                          \n",
      "correct=male     guess=female   name=Danie                         \n",
      "correct=male     guess=female   name=Dewey                         \n",
      "correct=male     guess=female   name=Donny                         \n",
      "correct=male     guess=female   name=Dougie                        \n",
      "correct=male     guess=female   name=Eddie                         \n",
      "correct=male     guess=female   name=Elijah                        \n",
      "correct=male     guess=female   name=Finley                        \n",
      "correct=male     guess=female   name=Gay                           \n",
      "correct=male     guess=female   name=Geoffry                       \n",
      "correct=male     guess=female   name=Gere                          \n",
      "correct=male     guess=female   name=Geri                          \n",
      "correct=male     guess=female   name=Giuseppe                      \n",
      "correct=male     guess=female   name=Gregory                       \n",
      "correct=male     guess=female   name=Hasty                         \n",
      "correct=male     guess=female   name=Herby                         \n",
      "correct=male     guess=female   name=Humphrey                      \n",
      "correct=male     guess=female   name=Hurley                        \n",
      "correct=male     guess=female   name=Ira                           \n",
      "correct=male     guess=female   name=Jeffery                       \n",
      "correct=male     guess=female   name=Jeffie                        \n",
      "correct=male     guess=female   name=Jefry                         \n",
      "correct=male     guess=female   name=Jeramie                       \n",
      "correct=male     guess=female   name=Jereme                        \n",
      "correct=male     guess=female   name=Jerzy                         \n",
      "correct=male     guess=female   name=Jodi                          \n",
      "correct=male     guess=female   name=Joey                          \n",
      "correct=male     guess=female   name=Joshua                        \n",
      "correct=male     guess=female   name=Kerry                         \n",
      "correct=male     guess=female   name=Kory                          \n",
      "correct=male     guess=female   name=Lefty                         \n",
      "correct=male     guess=female   name=Lonnie                        \n",
      "correct=male     guess=female   name=Luke                          \n",
      "correct=male     guess=female   name=Lyle                          \n",
      "correct=male     guess=female   name=Mackenzie                     \n",
      "correct=male     guess=female   name=Maxie                         \n",
      "correct=male     guess=female   name=Mika                          \n",
      "correct=male     guess=female   name=Mikey                         \n",
      "correct=male     guess=female   name=Monroe                        \n",
      "correct=male     guess=female   name=Monty                         \n",
      "correct=male     guess=female   name=Morrie                        \n",
      "correct=male     guess=female   name=Murdoch                       \n",
      "correct=male     guess=female   name=Nate                          \n",
      "correct=male     guess=female   name=Neale                         \n",
      "correct=male     guess=female   name=Nicky                         \n",
      "correct=male     guess=female   name=Obadiah                       \n",
      "correct=male     guess=female   name=Paddy                         \n",
      "correct=male     guess=female   name=Paige                         \n",
      "correct=male     guess=female   name=Patsy                         \n",
      "correct=male     guess=female   name=Petey                         \n",
      "correct=male     guess=female   name=Pierce                        \n",
      "correct=male     guess=female   name=Pierre                        \n",
      "correct=male     guess=female   name=Radcliffe                     \n",
      "correct=male     guess=female   name=Rafe                          \n",
      "correct=male     guess=female   name=Ramsay                        \n",
      "correct=male     guess=female   name=Randie                        \n",
      "correct=male     guess=female   name=Ravi                          \n",
      "correct=male     guess=female   name=Robbie                        \n",
      "correct=male     guess=female   name=Roice                         \n",
      "correct=male     guess=female   name=Rudie                         \n",
      "correct=male     guess=female   name=Rutledge                      \n",
      "correct=male     guess=female   name=Sammie                        \n",
      "correct=male     guess=female   name=Sandy                         \n",
      "correct=male     guess=female   name=Sarge                         \n",
      "correct=male     guess=female   name=Sascha                        \n",
      "correct=male     guess=female   name=Saxe                          \n",
      "correct=male     guess=female   name=Say                           \n",
      "correct=male     guess=female   name=Sayre                         \n",
      "correct=male     guess=female   name=Scottie                       \n",
      "correct=male     guess=female   name=Sergei                        \n",
      "correct=male     guess=female   name=Sheffy                        \n",
      "correct=male     guess=female   name=Sidnee                        \n",
      "correct=male     guess=female   name=Spike                         \n",
      "correct=male     guess=female   name=Stanleigh                     \n",
      "correct=male     guess=female   name=Sterne                        \n",
      "correct=male     guess=female   name=Stevie                        \n",
      "correct=male     guess=female   name=Tabbie                        \n",
      "correct=male     guess=female   name=Tallie                        \n",
      "correct=male     guess=female   name=Tammie                        \n",
      "correct=male     guess=female   name=Terrance                      \n",
      "correct=male     guess=female   name=Tobiah                        \n",
      "correct=male     guess=female   name=Toby                          \n",
      "correct=male     guess=female   name=Torrence                      \n",
      "correct=male     guess=female   name=Townie                        \n",
      "correct=male     guess=female   name=Tracy                         \n",
      "correct=male     guess=female   name=Vassili                       \n",
      "correct=male     guess=female   name=Vinnie                        \n",
      "correct=male     guess=female   name=Virge                         \n",
      "correct=male     guess=female   name=Wallache                      \n",
      "correct=male     guess=female   name=Waverly                       \n",
      "correct=male     guess=female   name=Welch                         \n",
      "correct=male     guess=female   name=Welsh                         \n",
      "correct=male     guess=female   name=Worthy                        \n",
      "correct=male     guess=female   name=Wylie                         \n",
      "correct=male     guess=female   name=Zane                          \n",
      "correct=male     guess=female   name=Zebadiah                      \n"
     ]
    }
   ],
   "source": [
    "for (tag, guess, name) in sorted(errors):\n",
    "    print('correct={:<8} guess={:<8s} name={:<30}'.format(tag, guess, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e71f462",
   "metadata": {},
   "source": [
    "Looking through this list of errors makes it clear that **some suffixes that are more than one letter can be indicative of name genders**. \n",
    "\n",
    "For example, names ending in *yn* appear to be predominantly female, despite the fact that names ending in *n* tend to be male; \n",
    "\n",
    "Names ending in *ch* are usually male, even though names that end in *h* tend to be female.\n",
    "\n",
    "We therefore adjust our feature extractor to **include features for two-letter suffixes**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43e682fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'suffix1': word[-1:],\n",
    "            'suffix2': word[-2:]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ad9d4",
   "metadata": {},
   "source": [
    "Rebuilding the classifier with the new feature extractor, the performance on the dev-test dataset improves slightly (76.3% -> 76.6%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "315b9e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.766\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96920d76",
   "metadata": {},
   "source": [
    "This **error analysis** procedure can then be **repeated**, checking for patterns in the errors that are made by the newly improved classifier. \n",
    "\n",
    "Each time the error analysis procedure is repeated, we should select **a different dev-test/training split**, to ensure that the classifier does not start to reflect idiosyncrasies in the dev-test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbb174b",
   "metadata": {},
   "source": [
    "Once our model development is complete with the help of the dev-test/training sets, we can use the test set to evaluate how well our model will perform on new input values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8cc28b",
   "metadata": {},
   "source": [
    "## 1.3   Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb2ae6e",
   "metadata": {},
   "source": [
    "For this example, we've chosen the Movie Reviews Corpus, which categorizes each review as positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f07a532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2438eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bcd3fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1331aa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['and', 'now', 'the', 'high', '-', 'flying', 'hong', 'kong', 'style', 'of', 'filmmaking', 'has', 'made', 'its', 'way', 'down', 'to', 'the', 'classics', ',', 'and', 'it', 'isn', \"'\", 't', 'pretty', '.', 'this', 'time', 'out', 'the', 'nod', 'to', 'asia', 'goes', 'by', 'way', 'of', 'france', 'in', 'the', 'excruciating', 'bland', 'and', 'lukewarm', 'production', 'of', 'the', 'musketeer', ',', 'a', 'version', 'of', 'dumas', \"'\", 's', 'the', 'three', 'musketeers', '.', 'by', 'bringing', 'in', 'popular', 'asian', 'actor', '/', 'stunt', 'coordinator', 'xing', 'xing', 'xiong', '--', 'whose', 'only', 'prior', 'american', 'attempts', 'at', 'stunt', 'choreography', 'have', 'been', 'the', 'laughable', 'van', 'damme', 'vehicle', 'double', 'team', 'and', 'the', 'dennis', 'rodman', 'cinematic', 'joke', 'simon', 'sez', '--', 'our', 'musketeers', 'are', 'thrown', 'into', 'the', 'air', 'to', 'do', 'their', 'fighting', '.', 'the', 'end', 'result', 'is', 'a', 'tepid', 'and', 'dull', 'action', '/', 'adventure', 'rip', '-', 'off', 'that', 'stinks', 'of', 'indiana', 'jones', 'and', 'bad', 'asian', 'kung', 'fu', '.', 'the', 'story', 'is', 'so', 'simple', 'my', 'grandmother', 'could', 'have', 'adapted', 'the', 'screenplay', '.', 'd', \"'\", 'artagnan', '(', 'justin', 'chambers', ')', 'is', 'the', 'vengeful', 'son', 'of', 'a', 'slain', 'musketeer', '.', 'he', 'travels', 'to', 'paris', 'to', 'join', 'the', 'royal', 'musketeers', 'and', 'find', 'the', 'man', 'that', 'killed', 'his', 'parents', '.', 'in', 'paris', ',', 'he', 'meets', 'the', 'cunning', 'cardinal', 'richelieu', '(', 'stephen', 'rea', ')', ',', 'who', 'is', 'trying', 'to', 'overthrow', 'the', 'king', ',', 'and', 'richelieu', \"'\", 's', 'man', '-', 'in', '-', 'black', 'associate', 'febre', '(', 'tim', 'roth', ')', ',', 'the', 'killer', 'of', 'his', 'folks', '.', 'he', 'finds', 'the', 'musketeers', 'in', 'paris', 'disbanded', 'and', 'drunk', ',', 'so', 'he', 'rounds', 'up', 'aramis', '(', 'nick', 'moran', ')', ',', 'athos', '(', 'jan', 'gregor', 'kremp', ')', 'and', 'porthos', '(', 'steven', 'spiers', ')', 'to', 'free', 'the', 'musketeer', \"'\", 's', 'wrongfully', 'imprisoned', 'leader', 'treville', 'from', 'the', 'king', \"'\", 's', 'prison', '.', 'd', \"'\", 'artagnan', 'and', 'his', 'new', 'frisky', 'love', 'interest', '/', 'chambermaid', 'francesca', '(', 'mena', 'suvari', ')', 'play', 'footsy', 'and', 'coo', 'at', 'each', 'other', 'as', 'the', 'cardinal', 'hunts', 'down', 'the', 'musketeers', 'until', 'finally', 'the', 'queen', '(', 'catherine', 'deneuve', ')', 'ends', 'up', 'being', 'captured', 'by', 'the', 'menancing', 'febre', ',', 'forcing', 'the', 'musketeers', 'to', 'regroup', ',', 'with', 'd', \"'\", 'artagnan', 'leading', 'the', 'charge', ',', 'and', 'save', 'the', 'day', '.', 'director', 'peter', 'hyams', '(', 'end', 'of', 'days', ')', 'obviously', 'wanted', 'to', 'blend', 'eastern', 'and', 'western', 'filmmaking', 'styles', ',', 'but', 'here', 'it', \"'\", 's', 'a', 'disaster', '.', 'one', 'problem', 'is', 'that', ',', 'in', 'reality', ',', 'most', 'eastern', 'films', 'have', 'taken', 'their', 'lead', 'from', 'western', 'ones', '.', 'jet', 'li', \"'\", 's', 'high', 'risk', 'is', 'a', 'rip', '-', 'off', 'of', 'die', 'hard', '--', 'not', 'the', 'other', 'way', 'around', '.', 'ironically', ',', 'there', 'is', 'awfully', 'little', 'swordplay', 'or', 'action', 'in', 'the', 'film', 'at', 'all', '--', 'maybe', 'ten', 'minutes', 'of', 'swashbuckling', 'spread', 'over', 'five', 'scenes', '.', 'most', 'asian', 'action', 'films', 'carry', 'the', 'bulk', 'of', 'their', 'production', 'with', '20', '-', 'to', '30', '-', 'minute', 'action', 'sequences', ',', 'because', 'they', 'know', 'the', 'scenes', 'have', 'to', 'carry', 'the', 'picture', '.', 'the', 'musketeer', 'instead', 'weighs', 'itself', 'down', 'with', 'a', 'predictable', 'and', 'monotonous', 'screenplay', 'by', 'gene', 'quintano', '(', 'sudden', 'death', ')', ',', 'horrible', 'acting', 'by', 'stephen', 'rea', 'and', 'tim', 'roth', ',', 'and', 'the', 'prosaic', 'attempt', 'of', 'justin', 'chambers', '(', 'the', 'wedding', 'planner', ')', 'to', 'deliver', 'his', 'mousy', 'self', 'as', 'a', 'leader', '.', 'chambers', \"'\", 'd', \"'\", 'artangnan', 'isn', \"'\", 't', 'a', 'musketeer', '--', 'he', \"'\", 's', 'a', 'mouseketeer', '!', 'and', 'hyam', \"'\", 's', 'use', 'of', 'candles', 'and', 'torches', 'to', 'light', 'the', 'grime', 'and', 'filth', 'of', '17th', 'century', 'paris', 'are', 'well', '-', 'noted', ',', 'but', 'that', \"'\", 's', 'the', 'only', 'standout', 'in', 'an', 'overall', 'flat', 'production', '.'], 'neg')\n"
     ]
    }
   ],
   "source": [
    "print(documents[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f59bbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3255ba41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78778720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents[12][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d41eb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents[12][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58c65db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652bc28e",
   "metadata": {},
   "source": [
    "Next, we define **a feature extractor** for documents, so the classifier will know **which aspects** of the data it should pay attention to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ef2b2e",
   "metadata": {},
   "source": [
    "To **limit the number of features** that the classifier needs to process, we begin by constructing **a list of the 2000 most frequent words** in the overall corpus.\n",
    "\n",
    "We can then define a feature extractor that simply **checks whether each of these words is present** in a given document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ab8698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "word_features = list(all_words)[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58a47dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', 'the', '.', 'a', 'and', 'of', 'to', \"'\", 'is', 'in', 's', '\"', 'it', 'that', '-', ')', '(', 'as', 'with', 'for', 'his', 'this', 'film', 'i', 'he', 'but', 'on', 'are', 't', 'by']\n"
     ]
    }
   ],
   "source": [
    "print(word_features[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01733d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d9537bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contains(,)': True, 'contains(the)': True, 'contains(.)': True, 'contains(a)': True, 'contains(and)': True, 'contains(of)': True, 'contains(to)': True, \"contains(')\": True, 'contains(is)': True, 'contains(in)': True, 'contains(s)': True, 'contains(\")': True, 'contains(it)': True, 'contains(that)': True, 'contains(-)': True, 'contains())': True, 'contains(()': True, 'contains(as)': True, 'contains(with)': True, 'contains(for)': True, 'contains(his)': True, 'contains(this)': True, 'contains(film)': False, 'contains(i)': False, 'contains(he)': True, 'contains(but)': True, 'contains(on)': True, 'contains(are)': True, 'contains(t)': False, 'contains(by)': True, 'contains(be)': True, 'contains(one)': True, 'contains(movie)': True, 'contains(an)': True, 'contains(who)': True, 'contains(not)': True, 'contains(you)': True, 'contains(from)': True, 'contains(at)': False, 'contains(was)': False, 'contains(have)': True, 'contains(they)': True, 'contains(has)': True, 'contains(her)': False, 'contains(all)': True, 'contains(?)': False, 'contains(there)': True, 'contains(like)': True, 'contains(so)': False, 'contains(out)': True, 'contains(about)': True, 'contains(up)': False, 'contains(more)': False, 'contains(what)': True, 'contains(when)': True, 'contains(which)': True, 'contains(or)': False, 'contains(she)': True, 'contains(their)': False, 'contains(:)': True, 'contains(some)': False, 'contains(just)': True, 'contains(can)': False, 'contains(if)': True, 'contains(we)': False, 'contains(him)': True, 'contains(into)': True, 'contains(even)': False, 'contains(only)': True, 'contains(than)': False, 'contains(no)': False, 'contains(good)': False, 'contains(time)': False, 'contains(most)': True, 'contains(its)': False, 'contains(will)': True, 'contains(story)': False, 'contains(would)': False, 'contains(been)': False, 'contains(much)': False, 'contains(character)': False, 'contains(also)': True, 'contains(get)': True, 'contains(other)': True, 'contains(do)': True, 'contains(two)': True, 'contains(well)': True, 'contains(them)': True, 'contains(very)': True, 'contains(characters)': False, 'contains(;)': False, 'contains(first)': False, 'contains(--)': True, 'contains(after)': False, 'contains(see)': False, 'contains(!)': True, 'contains(way)': True, 'contains(because)': False, 'contains(make)': True, 'contains(life)': False, 'contains(off)': False, 'contains(too)': False, 'contains(any)': False, 'contains(does)': False, 'contains(really)': False, 'contains(had)': False, 'contains(while)': True, 'contains(films)': False, 'contains(how)': True, 'contains(plot)': True, 'contains(little)': True, 'contains(where)': True, 'contains(people)': False, 'contains(over)': False, 'contains(could)': False, 'contains(then)': True, 'contains(me)': True, 'contains(scene)': True, 'contains(man)': False, 'contains(bad)': False, 'contains(my)': False, 'contains(never)': True, 'contains(being)': False, 'contains(best)': True, 'contains(these)': False, 'contains(don)': False, 'contains(new)': False, 'contains(doesn)': False, 'contains(scenes)': False, 'contains(many)': True, 'contains(director)': False, 'contains(such)': False, 'contains(know)': False, 'contains(were)': False, 'contains(movies)': True, 'contains(through)': False, 'contains(here)': True, 'contains(action)': True, 'contains(great)': True, 'contains(re)': True, 'contains(another)': False, 'contains(love)': False, 'contains(go)': False, 'contains(made)': False, 'contains(us)': True, 'contains(big)': False, 'contains(end)': False, 'contains(something)': False, 'contains(back)': False, 'contains(*)': True, 'contains(still)': False, 'contains(world)': True, 'contains(seems)': False, 'contains(work)': False, 'contains(those)': False, 'contains(makes)': False, 'contains(now)': False, 'contains(before)': False, 'contains(however)': True, 'contains(between)': True, 'contains(few)': False, 'contains(/)': False, 'contains(down)': False, 'contains(every)': False, 'contains(though)': False, 'contains(better)': False, 'contains(real)': False, 'contains(audience)': False, 'contains(enough)': False, 'contains(seen)': False, 'contains(take)': False, 'contains(around)': False, 'contains(both)': False, 'contains(going)': False, 'contains(year)': False, 'contains(performance)': False, 'contains(why)': False, 'contains(should)': False, 'contains(role)': False, 'contains(isn)': False, 'contains(same)': True, 'contains(old)': False, 'contains(gets)': True, 'contains(your)': False, 'contains(may)': False, 'contains(things)': True, 'contains(think)': False, 'contains(years)': False, 'contains(last)': False, 'contains(comedy)': True, 'contains(funny)': True, 'contains(actually)': True, 'contains(ve)': False, 'contains(long)': False, 'contains(look)': True, 'contains(almost)': False, 'contains(own)': True, 'contains(thing)': False, 'contains(fact)': False, 'contains(nothing)': False, 'contains(say)': False, 'contains(right)': False, 'contains(john)': False, 'contains(although)': False, 'contains(played)': True, 'contains(find)': False, 'contains(script)': False, 'contains(come)': False, 'contains(ever)': True, 'contains(cast)': False, 'contains(since)': False, 'contains(did)': False, 'contains(star)': False, 'contains(plays)': False, 'contains(young)': False, 'contains(show)': False, 'contains(comes)': False, 'contains(m)': False, 'contains(part)': False, 'contains(original)': False, 'contains(actors)': False, 'contains(screen)': True, 'contains(without)': False, 'contains(again)': False, 'contains(acting)': False, 'contains(three)': False, 'contains(day)': True, 'contains(each)': True, 'contains(point)': False, 'contains(lot)': False, 'contains(least)': True, 'contains(takes)': False, 'contains(guy)': True, 'contains(quite)': False, 'contains(himself)': False, 'contains(away)': False, 'contains(during)': False, 'contains(family)': False, 'contains(effects)': False, 'contains(course)': True, 'contains(goes)': False, 'contains(minutes)': False, 'contains(interesting)': False, 'contains(might)': False, 'contains(far)': False, 'contains(high)': False, 'contains(rather)': False, 'contains(once)': True, 'contains(must)': False, 'contains(anything)': False, 'contains(place)': True, 'contains(set)': False, 'contains(yet)': False, 'contains(watch)': True, 'contains(d)': False, 'contains(making)': True, 'contains(our)': False, 'contains(wife)': True, 'contains(hard)': False, 'contains(always)': False, 'contains(fun)': True, 'contains(didn)': False, 'contains(ll)': False, 'contains(seem)': False, 'contains(special)': False, 'contains(bit)': False, 'contains(times)': False, 'contains(trying)': False, 'contains(hollywood)': False, 'contains(instead)': False, 'contains(give)': False, 'contains(want)': False, 'contains(picture)': False, 'contains(kind)': True, 'contains(american)': False, 'contains(job)': False, 'contains(sense)': False, 'contains(woman)': True, 'contains(home)': False, 'contains(having)': False, 'contains(series)': True, 'contains(actor)': False, 'contains(probably)': False, 'contains(help)': True, 'contains(half)': False, 'contains(along)': True, 'contains(men)': False, 'contains(everything)': True, 'contains(pretty)': False, 'contains(becomes)': False, 'contains(sure)': False, 'contains(black)': False, 'contains(together)': False, 'contains(dialogue)': False, 'contains(money)': False, 'contains(become)': False, 'contains(gives)': False, 'contains(given)': False, 'contains(looking)': False, 'contains(whole)': False, 'contains(watching)': False, 'contains(father)': False, 'contains(`)': False, 'contains(feel)': False, 'contains(everyone)': False, 'contains(music)': False, 'contains(wants)': False, 'contains(sex)': False, 'contains(less)': False, 'contains(done)': False, 'contains(horror)': False, 'contains(got)': True, 'contains(death)': False, 'contains(perhaps)': False, 'contains(city)': False, 'contains(next)': False, 'contains(especially)': True, 'contains(play)': False, 'contains(girl)': False, 'contains(mind)': False, 'contains(10)': False, 'contains(moments)': False, 'contains(looks)': True, 'contains(completely)': False, 'contains(2)': False, 'contains(reason)': False, 'contains(mother)': False, 'contains(whose)': False, 'contains(line)': False, 'contains(night)': False, 'contains(human)': False, 'contains(until)': False, 'contains(rest)': False, 'contains(performances)': False, 'contains(different)': False, 'contains(evil)': False, 'contains(small)': False, 'contains(james)': False, 'contains(simply)': False, 'contains(couple)': False, 'contains(put)': False, 'contains(let)': False, 'contains(anyone)': False, 'contains(ending)': False, 'contains(case)': False, 'contains(several)': False, 'contains(dead)': False, 'contains(michael)': False, 'contains(left)': False, 'contains(thought)': False, 'contains(school)': False, 'contains(shows)': False, 'contains(humor)': False, 'contains(true)': False, 'contains(lost)': False, 'contains(written)': False, 'contains(itself)': False, 'contains(friend)': False, 'contains(entire)': False, 'contains(getting)': True, 'contains(town)': False, 'contains(turns)': False, 'contains(soon)': False, 'contains(someone)': False, 'contains(second)': False, 'contains(main)': False, 'contains(stars)': False, 'contains(found)': False, 'contains(use)': False, 'contains(problem)': False, 'contains(friends)': True, 'contains(tv)': False, 'contains(top)': True, 'contains(name)': False, 'contains(begins)': False, 'contains(called)': False, 'contains(based)': False, 'contains(comic)': False, 'contains(david)': False, 'contains(head)': False, 'contains(else)': False, 'contains(idea)': True, 'contains(either)': False, 'contains(wrong)': True, 'contains(unfortunately)': False, 'contains(later)': False, 'contains(final)': False, 'contains(hand)': False, 'contains(alien)': False, 'contains(house)': False, 'contains(group)': False, 'contains(full)': False, 'contains(used)': True, 'contains(tries)': True, 'contains(often)': True, 'contains(against)': False, 'contains(war)': False, 'contains(sequence)': False, 'contains(keep)': False, 'contains(turn)': False, 'contains(playing)': True, 'contains(boy)': False, 'contains(behind)': False, 'contains(named)': False, 'contains(certainly)': False, 'contains(live)': False, 'contains(believe)': False, 'contains(under)': False, 'contains(works)': False, 'contains(relationship)': False, 'contains(face)': False, 'contains(hour)': False, 'contains(run)': False, 'contains(style)': False, 'contains(said)': False, 'contains(despite)': False, 'contains(person)': False, 'contains(finally)': False, 'contains(shot)': False, 'contains(book)': False, 'contains(doing)': False, 'contains(tell)': False, 'contains(maybe)': False, 'contains(nice)': False, 'contains(son)': False, 'contains(perfect)': False, 'contains(side)': False, 'contains(seeing)': True, 'contains(able)': False, 'contains(finds)': False, 'contains(children)': False, 'contains(days)': False, 'contains(past)': False, 'contains(summer)': False, 'contains(camera)': False, 'contains(won)': False, 'contains(including)': False, 'contains(mr)': False, 'contains(kids)': False, 'contains(lives)': False, 'contains(directed)': False, 'contains(moment)': False, 'contains(game)': False, 'contains(running)': False, 'contains(fight)': True, 'contains(supposed)': False, 'contains(video)': False, 'contains(car)': False, 'contains(matter)': False, 'contains(kevin)': True, 'contains(joe)': False, 'contains(lines)': False, 'contains(worth)': True, 'contains(=)': False, 'contains(daughter)': False, 'contains(earth)': False, 'contains(starts)': False, 'contains(need)': False, 'contains(entertaining)': False, 'contains(white)': False, 'contains(start)': True, 'contains(writer)': False, 'contains(dark)': False, 'contains(short)': False, 'contains(self)': False, 'contains(worst)': False, 'contains(nearly)': False, 'contains(opening)': False, 'contains(try)': False, 'contains(upon)': False, 'contains(care)': False, 'contains(early)': True, 'contains(violence)': False, 'contains(throughout)': False, 'contains(team)': False, 'contains(production)': False, 'contains(example)': False, 'contains(beautiful)': False, 'contains(title)': False, 'contains(exactly)': False, 'contains(jack)': False, 'contains(review)': False, 'contains(major)': False, 'contains(drama)': False, 'contains(&)': False, 'contains(problems)': True, 'contains(sequences)': False, 'contains(obvious)': False, 'contains(version)': False, 'contains(screenplay)': False, 'contains(known)': True, 'contains(killer)': False, 'contains(wasn)': False, 'contains(robert)': False, 'contains(disney)': False, 'contains(already)': False, 'contains(close)': False, 'contains(classic)': False, 'contains(others)': True, 'contains(hit)': False, 'contains(kill)': False, 'contains(deep)': True, 'contains(five)': False, 'contains(order)': False, 'contains(act)': False, 'contains(simple)': False, 'contains(fine)': False, 'contains(themselves)': False, 'contains(heart)': False, 'contains(roles)': False, 'contains(jackie)': True, 'contains(direction)': False, 'contains(eyes)': False, 'contains(four)': False, 'contains(question)': False, 'contains(sort)': False, 'contains(sometimes)': False, 'contains(knows)': False, 'contains(supporting)': False, 'contains(coming)': False, 'contains(voice)': False, 'contains(women)': False, 'contains(truly)': False, 'contains(save)': False, 'contains(jokes)': False, 'contains(computer)': False, 'contains(child)': False, 'contains(o)': False, 'contains(boring)': False, 'contains(tom)': False, 'contains(level)': False, 'contains(1)': False, 'contains(body)': False, 'contains(guys)': False, 'contains(genre)': False, 'contains(brother)': False, 'contains(strong)': False, 'contains(stop)': True, 'contains(room)': False, 'contains(space)': False, 'contains(lee)': False, 'contains(ends)': False, 'contains(beginning)': False, 'contains(ship)': False, 'contains(york)': False, 'contains(attempt)': False, 'contains(thriller)': False, 'contains(scream)': True, 'contains(peter)': False, 'contains(aren)': False, 'contains(husband)': False, 'contains(fiction)': False, 'contains(happens)': False, 'contains(hero)': False, 'contains(novel)': False, 'contains(note)': False, 'contains(hope)': False, 'contains(king)': False, 'contains(yes)': False, 'contains(says)': False, 'contains(tells)': False, 'contains(quickly)': False, 'contains(romantic)': False, 'contains(dog)': False, 'contains(oscar)': False, 'contains(stupid)': False, 'contains(possible)': False, 'contains(saw)': False, 'contains(lead)': True, 'contains(career)': False, 'contains(murder)': False, 'contains(extremely)': False, 'contains(manages)': False, 'contains(god)': False, 'contains(mostly)': False, 'contains(wonder)': False, 'contains(particularly)': False, 'contains(future)': False, 'contains(fans)': False, 'contains(sound)': False, 'contains(worse)': False, 'contains(piece)': False, 'contains(involving)': False, 'contains(de)': False, 'contains(appears)': False, 'contains(planet)': False, 'contains(paul)': False, 'contains(involved)': False, 'contains(mean)': False, 'contains(none)': False, 'contains(taking)': False, 'contains(hours)': False, 'contains(laugh)': True, 'contains(police)': False, 'contains(sets)': False, 'contains(attention)': False, 'contains(co)': False, 'contains(hell)': False, 'contains(eventually)': False, 'contains(single)': False, 'contains(fall)': False, 'contains(falls)': False, 'contains(material)': False, 'contains(emotional)': False, 'contains(power)': False, 'contains(late)': False, 'contains(lack)': False, 'contains(dr)': False, 'contains(van)': False, 'contains(result)': False, 'contains(elements)': False, 'contains(meet)': False, 'contains(smith)': False, 'contains(science)': False, 'contains(experience)': False, 'contains(bring)': False, 'contains(wild)': False, 'contains(living)': False, 'contains(theater)': False, 'contains(interest)': False, 'contains(leads)': False, 'contains(word)': False, 'contains(feature)': False, 'contains(battle)': False, 'contains(girls)': False, 'contains(alone)': False, 'contains(obviously)': False, 'contains(george)': False, 'contains(within)': False, 'contains(usually)': False, 'contains(enjoy)': False, 'contains(guess)': False, 'contains(among)': True, 'contains(taken)': False, 'contains(feeling)': False, 'contains(laughs)': False, 'contains(aliens)': False, 'contains(talk)': True, 'contains(chance)': False, 'contains(talent)': False, 'contains(3)': False, 'contains(middle)': False, 'contains(number)': False, 'contains(easy)': False, 'contains(across)': False, 'contains(needs)': False, 'contains(attempts)': False, 'contains(happen)': False, 'contains(television)': False, 'contains(chris)': False, 'contains(deal)': False, 'contains(poor)': False, 'contains(form)': False, 'contains(girlfriend)': True, 'contains(viewer)': False, 'contains(release)': False, 'contains(killed)': False, 'contains(forced)': False, 'contains(whether)': False, 'contains(wonderful)': False, 'contains(feels)': False, 'contains(oh)': False, 'contains(tale)': False, 'contains(serious)': False, 'contains(expect)': False, 'contains(except)': False, 'contains(light)': False, 'contains(success)': False, 'contains(features)': True, 'contains(premise)': False, 'contains(happy)': False, 'contains(words)': False, 'contains(leave)': False, 'contains(important)': False, 'contains(meets)': False, 'contains(history)': False, 'contains(giving)': False, 'contains(crew)': False, 'contains(type)': False, 'contains(call)': False, 'contains(turned)': False, 'contains(released)': False, 'contains(parents)': False, 'contains(art)': False, 'contains(impressive)': False, 'contains(mission)': False, 'contains(working)': False, 'contains(seemed)': False, 'contains(score)': False, 'contains(told)': False, 'contains(recent)': False, 'contains(robin)': False, 'contains(basically)': False, 'contains(entertainment)': False, 'contains(america)': False, 'contains($)': False, 'contains(surprise)': False, 'contains(apparently)': False, 'contains(easily)': False, 'contains(ryan)': False, 'contains(cool)': False, 'contains(stuff)': False, 'contains(cop)': False, 'contains(change)': False, 'contains(williams)': False, 'contains(crime)': False, 'contains(office)': False, 'contains(parts)': False, 'contains(somehow)': False, 'contains(sequel)': False, 'contains(william)': False, 'contains(cut)': False, 'contains(die)': False, 'contains(jones)': False, 'contains(credits)': False, 'contains(batman)': False, 'contains(suspense)': False, 'contains(brings)': False, 'contains(events)': False, 'contains(reality)': False, 'contains(whom)': False, 'contains(local)': False, 'contains(talking)': False, 'contains(difficult)': True, 'contains(using)': False, 'contains(went)': False, 'contains(writing)': False, 'contains(remember)': False, 'contains(near)': False, 'contains(straight)': False, 'contains(hilarious)': True, 'contains(ago)': False, 'contains(certain)': False, 'contains(ben)': False, 'contains(kid)': False, 'contains(wouldn)': False, 'contains(slow)': True, 'contains(blood)': False, 'contains(mystery)': False, 'contains(complete)': False, 'contains(red)': False, 'contains(popular)': False, 'contains(effective)': False, 'contains(am)': False, 'contains(fast)': True, 'contains(flick)': False, 'contains(due)': False, 'contains(runs)': False, 'contains(gone)': False, 'contains(return)': False, 'contains(presence)': False, 'contains(quality)': False, 'contains(dramatic)': False, 'contains(filmmakers)': False, 'contains(age)': False, 'contains(brothers)': False, 'contains(business)': False, 'contains(general)': False, 'contains(rock)': False, 'contains(sexual)': False, 'contains(present)': False, 'contains(surprisingly)': False, 'contains(anyway)': False, 'contains(uses)': False, 'contains(4)': False, 'contains(personal)': False, 'contains(figure)': False, 'contains(smart)': False, 'contains(ways)': False, 'contains(decides)': False, 'contains(annoying)': False, 'contains(begin)': False, 'contains(couldn)': False, 'contains(somewhat)': False, 'contains(shots)': False, 'contains(rich)': False, 'contains(minute)': False, 'contains(law)': False, 'contains(previous)': False, 'contains(jim)': False, 'contains(successful)': False, 'contains(harry)': False, 'contains(water)': False, 'contains(similar)': False, 'contains(absolutely)': False, 'contains(motion)': False, 'contains(former)': False, 'contains(strange)': False, 'contains(came)': False, 'contains(follow)': False, 'contains(read)': False, 'contains(project)': False, 'contains(million)': True, 'contains(secret)': False, 'contains(starring)': False, 'contains(clear)': False, 'contains(familiar)': False, 'contains(romance)': False, 'contains(intelligent)': False, 'contains(third)': True, 'contains(excellent)': False, 'contains(amazing)': False, 'contains(party)': False, 'contains(budget)': False, 'contains(eye)': False, 'contains(actress)': False, 'contains(prison)': False, 'contains(latest)': False, 'contains(means)': True, 'contains(company)': False, 'contains(towards)': False, 'contains(predictable)': False, 'contains(powerful)': False, 'contains(nor)': False, 'contains(bob)': False, 'contains(beyond)': False, 'contains(visual)': False, 'contains(leaves)': False, 'contains(r)': False, 'contains(nature)': False, 'contains(following)': False, 'contains(villain)': False, 'contains(leaving)': False, 'contains(animated)': False, 'contains(low)': False, 'contains(myself)': False, 'contains(b)': False, 'contains(bill)': False, 'contains(sam)': False, 'contains(filled)': False, 'contains(wars)': False, 'contains(questions)': False, 'contains(cinema)': False, 'contains(message)': False, 'contains(box)': False, 'contains(moving)': True, 'contains(herself)': False, 'contains(country)': False, 'contains(usual)': False, 'contains(martin)': False, 'contains(definitely)': False, 'contains(add)': False, 'contains(large)': False, 'contains(clever)': False, 'contains(create)': False, 'contains(felt)': False, 'contains(stories)': False, 'contains(brilliant)': False, 'contains(ones)': False, 'contains(giant)': False, 'contains(situation)': False, 'contains(murphy)': False, 'contains(break)': False, 'contains(opens)': False, 'contains(scary)': False, 'contains(doubt)': False, 'contains(drug)': True, 'contains(bunch)': False, 'contains(thinking)': False, 'contains(solid)': False, 'contains(effect)': False, 'contains(learn)': False, 'contains(move)': False, 'contains(force)': False, 'contains(potential)': False, 'contains(seriously)': False, 'contains(follows)': False, 'contains(above)': False, 'contains(saying)': False, 'contains(huge)': False, 'contains(class)': False, 'contains(plan)': False, 'contains(agent)': False, 'contains(created)': False, 'contains(unlike)': False, 'contains(pay)': False, 'contains(non)': True, 'contains(married)': False, 'contains(mark)': False, 'contains(sweet)': False, 'contains(perfectly)': False, 'contains(ex)': False, 'contains(realize)': False, 'contains(audiences)': False, 'contains(took)': False, 'contains(decent)': False, 'contains(likely)': False, 'contains(dream)': False, 'contains(view)': False, 'contains(scott)': False, 'contains(subject)': False, 'contains(understand)': False, 'contains(happened)': False, 'contains(enjoyable)': True, 'contains(studio)': False, 'contains(immediately)': False, 'contains(open)': False, 'contains(e)': False, 'contains(points)': False, 'contains(heard)': False, 'contains(viewers)': False, 'contains(cameron)': False, 'contains(truman)': False, 'contains(bruce)': False, 'contains(frank)': False, 'contains(private)': False, 'contains(stay)': False, 'contains(fails)': False, 'contains(impossible)': False, 'contains(cold)': False, 'contains(richard)': False, 'contains(overall)': False, 'contains(merely)': False, 'contains(exciting)': False, 'contains(mess)': False, 'contains(chase)': True, 'contains(free)': False, 'contains(ten)': False, 'contains(neither)': False, 'contains(wanted)': False, 'contains(gun)': True, 'contains(appear)': False, 'contains(carter)': False, 'contains(escape)': False, 'contains(ultimately)': False, 'contains(+)': False, 'contains(fan)': False, 'contains(inside)': False, 'contains(favorite)': False, 'contains(haven)': False, 'contains(modern)': False, 'contains(l)': False, 'contains(wedding)': False, 'contains(stone)': False, 'contains(trek)': False, 'contains(brought)': False, 'contains(trouble)': True, 'contains(otherwise)': False, 'contains(tim)': False, 'contains(5)': False, 'contains(allen)': False, 'contains(bond)': False, 'contains(society)': False, 'contains(liked)': False, 'contains(dumb)': False, 'contains(musical)': False, 'contains(stand)': False, 'contains(political)': False, 'contains(various)': False, 'contains(talented)': False, 'contains(particular)': False, 'contains(west)': False, 'contains(state)': False, 'contains(keeps)': True, 'contains(english)': False, 'contains(silly)': False, 'contains(u)': False, 'contains(situations)': False, 'contains(park)': False, 'contains(teen)': False, 'contains(rating)': False, 'contains(slightly)': False, 'contains(steve)': False, 'contains(truth)': False, 'contains(air)': False, 'contains(element)': False, 'contains(joke)': False, 'contains(spend)': False, 'contains(key)': True, 'contains(biggest)': False, 'contains(members)': False, 'contains(effort)': False, 'contains(government)': False, 'contains(focus)': False, 'contains(eddie)': False, 'contains(soundtrack)': False, 'contains(hands)': False, 'contains(earlier)': False, 'contains(chan)': True, 'contains(purpose)': False, 'contains(today)': True, 'contains(showing)': False, 'contains(memorable)': False, 'contains(six)': False, 'contains(cannot)': False, 'contains(max)': False, 'contains(offers)': False, 'contains(rated)': False, 'contains(mars)': False, 'contains(heavy)': False, 'contains(totally)': False, 'contains(control)': False, 'contains(credit)': False, 'contains(fi)': False, 'contains(woody)': False, 'contains(ideas)': False, 'contains(sci)': False, 'contains(wait)': False, 'contains(sit)': False, 'contains(female)': False, 'contains(ask)': False, 'contains(waste)': False, 'contains(terrible)': False, 'contains(depth)': False, 'contains(simon)': False, 'contains(aspect)': False, 'contains(list)': False, 'contains(mary)': False, 'contains(sister)': False, 'contains(animation)': False, 'contains(entirely)': False, 'contains(fear)': False, 'contains(steven)': False, 'contains(moves)': False, 'contains(actual)': False, 'contains(army)': False, 'contains(british)': False, 'contains(constantly)': False, 'contains(fire)': False, 'contains(convincing)': False, 'contains(setting)': False, 'contains(gave)': False, 'contains(tension)': False, 'contains(street)': False, 'contains(8)': False, 'contains(brief)': True, 'contains(ridiculous)': False, 'contains(cinematography)': False, 'contains(typical)': False, 'contains(nick)': False, 'contains(screenwriter)': False, 'contains(ability)': False, 'contains(spent)': False, 'contains(quick)': True, 'contains(violent)': False, 'contains(atmosphere)': False, 'contains(subtle)': False, 'contains(expected)': False, 'contains(fairly)': True, 'contains(seven)': False, 'contains(killing)': False, 'contains(tone)': False, 'contains(master)': False, 'contains(disaster)': False, 'contains(lots)': False, 'contains(thinks)': False, 'contains(song)': False, 'contains(cheap)': False, 'contains(suddenly)': False, 'contains(background)': False, 'contains(club)': False, 'contains(willis)': False, 'contains(whatever)': False, 'contains(highly)': False, 'contains(sees)': True, 'contains(complex)': False, 'contains(greatest)': False, 'contains(impact)': False, 'contains(beauty)': False, 'contains(front)': False, 'contains(humans)': False, 'contains(indeed)': False, 'contains(flat)': False, 'contains(grace)': False, 'contains(wrote)': False, 'contains(amusing)': False, 'contains(ii)': False, 'contains(mike)': False, 'contains(further)': False, 'contains(cute)': False, 'contains(dull)': False, 'contains(minor)': False, 'contains(recently)': False, 'contains(hate)': False, 'contains(outside)': False, 'contains(plenty)': False, 'contains(wish)': False, 'contains(godzilla)': False, 'contains(college)': False, 'contains(titanic)': False, 'contains(sounds)': False, 'contains(telling)': False, 'contains(sight)': False, 'contains(double)': False, 'contains(cinematic)': False, 'contains(queen)': False, 'contains(hold)': False, 'contains(meanwhile)': False, 'contains(awful)': False, 'contains(clearly)': False, 'contains(theme)': False, 'contains(hear)': False, 'contains(x)': False, 'contains(amount)': False, 'contains(baby)': False, 'contains(approach)': False, 'contains(dreams)': False, 'contains(shown)': False, 'contains(island)': False, 'contains(reasons)': False, 'contains(charm)': False, 'contains(miss)': True, 'contains(longer)': False, 'contains(common)': False, 'contains(sean)': False, 'contains(carry)': False, 'contains(believable)': False, 'contains(realistic)': False, 'contains(chemistry)': True, 'contains(possibly)': False, 'contains(casting)': False, 'contains(carrey)': False, 'contains(french)': False, 'contains(trailer)': False, 'contains(tough)': False, 'contains(produced)': False, 'contains(imagine)': False, 'contains(choice)': False, 'contains(ride)': False, 'contains(somewhere)': False, 'contains(hot)': False, 'contains(race)': False, 'contains(road)': False, 'contains(leader)': False, 'contains(thin)': False, 'contains(jerry)': False, 'contains(slowly)': False, 'contains(delivers)': False, 'contains(detective)': False, 'contains(brown)': False, 'contains(jackson)': False, 'contains(member)': False, 'contains(provide)': False, 'contains(president)': False, 'contains(puts)': False, 'contains(asks)': False, 'contains(critics)': False, 'contains(appearance)': False, 'contains(famous)': False, 'contains(okay)': False, 'contains(intelligence)': False, 'contains(energy)': False, 'contains(sent)': False, 'contains(spielberg)': False, 'contains(development)': False, 'contains(etc)': False, 'contains(language)': False, 'contains(blue)': False, 'contains(proves)': False, 'contains(vampire)': False, 'contains(seemingly)': False, 'contains(basic)': False, 'contains(caught)': False, 'contains(decide)': False, 'contains(opportunity)': False, 'contains(incredibly)': False, 'contains(images)': False, 'contains(band)': False, 'contains(j)': False, 'contains(writers)': False, 'contains(knew)': False, 'contains(interested)': False, 'contains(considering)': False, 'contains(boys)': False, 'contains(thanks)': False, 'contains(remains)': False, 'contains(climax)': True, 'contains(event)': False, 'contains(directing)': False, 'contains(conclusion)': False, 'contains(leading)': False, 'contains(ground)': False, 'contains(lies)': False, 'contains(forget)': False, 'contains(alive)': False, 'contains(tarzan)': False, 'contains(century)': False, 'contains(provides)': False, 'contains(trip)': False, 'contains(partner)': False, 'contains(central)': False, 'contains(tarantino)': False, 'contains(period)': False, 'contains(pace)': False, 'contains(yourself)': False, 'contains(worked)': False, 'contains(ready)': False, 'contains(date)': False, 'contains(thus)': False, 'contains(1998)': False, 'contains(terrific)': False, 'contains(write)': False, 'contains(average)': False, 'contains(onto)': False, 'contains(songs)': False, 'contains(occasionally)': False, 'contains(doctor)': False, 'contains(stands)': False, 'contains(hardly)': False, 'contains(monster)': False, 'contains(led)': False, 'contains(mysterious)': False, 'contains(details)': False, 'contains(wasted)': False, 'contains(apart)': False, 'contains(aside)': False, 'contains(store)': False, 'contains(billy)': False, 'contains(boss)': True, 'contains(travolta)': False, 'contains(producer)': False, 'contains(pull)': False, 'contains(consider)': False, 'contains(pictures)': False, 'contains(becoming)': False, 'contains(cage)': False, 'contains(loud)': False, 'contains(looked)': False, 'contains(officer)': False, 'contains(twenty)': False, 'contains(system)': False, 'contains(contains)': False, 'contains(julia)': False, 'contains(subplot)': False, 'contains(missing)': False, 'contains(personality)': False, 'contains(building)': False, 'contains(learns)': False, 'contains(hong)': True, 'contains(la)': False, 'contains(apartment)': False, 'contains(7)': False, 'contains(bizarre)': False, 'contains(powers)': False, 'contains(flaws)': False, 'contains(catch)': False, 'contains(lawyer)': False, 'contains(shoot)': False, 'contains(student)': False, 'contains(unique)': True, 'contains(000)': False, 'contains(admit)': False, 'contains(concept)': False, 'contains(needed)': False, 'contains(thrown)': False, 'contains(christopher)': False, 'contains(laughing)': False, 'contains(green)': False, 'contains(twists)': False, 'contains(matthew)': False, 'contains(touch)': False, 'contains(waiting)': False, 'contains(victim)': False, 'contains(cover)': False, 'contains(machine)': False, 'contains(danny)': False, 'contains(mention)': False, 'contains(search)': False, 'contains(1997)': False, 'contains(win)': False, 'contains(door)': False, 'contains(manner)': False, 'contains(train)': True, 'contains(saving)': False, 'contains(share)': False, 'contains(image)': False, 'contains(discovers)': False, 'contains(normal)': False, 'contains(cross)': False, 'contains(fox)': False, 'contains(returns)': False, 'contains(adult)': False, 'contains(adds)': False, 'contains(answer)': False, 'contains(adventure)': False, 'contains(lame)': False, 'contains(male)': False, 'contains(odd)': False, 'contains(singer)': False, 'contains(deserves)': False, 'contains(gore)': False, 'contains(states)': False, 'contains(include)': False, 'contains(equally)': False, 'contains(months)': False, 'contains(barely)': False, 'contains(directors)': False, 'contains(introduced)': False, 'contains(fashion)': False, 'contains(social)': False, 'contains(1999)': False, 'contains(news)': False, 'contains(hair)': False, 'contains(dance)': False, 'contains(innocent)': False, 'contains(camp)': False, 'contains(teacher)': False, 'contains(became)': False, 'contains(sad)': False, 'contains(witch)': False, 'contains(includes)': False, 'contains(nights)': False, 'contains(jason)': False, 'contains(julie)': False, 'contains(latter)': False, 'contains(food)': True, 'contains(jennifer)': False, 'contains(land)': False, 'contains(menace)': False, 'contains(rate)': False, 'contains(storyline)': False, 'contains(contact)': False, 'contains(jean)': False, 'contains(elizabeth)': False, 'contains(fellow)': False, 'contains(changes)': False, 'contains(henry)': False, 'contains(hill)': False, 'contains(pulp)': False, 'contains(gay)': False, 'contains(tried)': False, 'contains(surprised)': False, 'contains(literally)': False, 'contains(walk)': False, 'contains(standard)': False, 'contains(90)': False, 'contains(forward)': False, 'contains(wise)': False, 'contains(enjoyed)': False, 'contains(discover)': False, 'contains(pop)': False, 'contains(anderson)': False, 'contains(offer)': False, 'contains(recommend)': False, 'contains(public)': False, 'contains(drive)': False, 'contains(c)': False, 'contains(toy)': False, 'contains(charming)': False, 'contains(fair)': False, 'contains(chinese)': True, 'contains(rescue)': False, 'contains(terms)': False, 'contains(mouth)': False, 'contains(lucas)': False, 'contains(accident)': False, 'contains(dies)': False, 'contains(decided)': False, 'contains(edge)': False, 'contains(footage)': False, 'contains(culture)': False, 'contains(weak)': False, 'contains(presented)': False, 'contains(blade)': False, 'contains(younger)': False, 'contains(douglas)': False, 'contains(natural)': False, 'contains(born)': False, 'contains(generally)': False, 'contains(teenage)': False, 'contains(older)': False, 'contains(horrible)': False, 'contains(addition)': False, 'contains(sadly)': False, 'contains(creates)': False, 'contains(disturbing)': False, 'contains(roger)': False, 'contains(detail)': False, 'contains(devil)': False, 'contains(debut)': False, 'contains(track)': False, 'contains(developed)': False, 'contains(week)': False, 'contains(russell)': False, 'contains(attack)': False, 'contains(explain)': False, 'contains(rarely)': False, 'contains(fully)': False, 'contains(prove)': False, 'contains(exception)': False, 'contains(jeff)': False, 'contains(twist)': False, 'contains(gang)': False, 'contains(winning)': False, 'contains(jr)': False, 'contains(species)': False, 'contains(issues)': False, 'contains(fresh)': False, 'contains(rules)': False, 'contains(meaning)': False, 'contains(inspired)': False, 'contains(heroes)': False, 'contains(desperate)': False, 'contains(fighting)': False, 'contains(filmed)': False, 'contains(faces)': False, 'contains(alan)': False, 'contains(bright)': False, 'contains(ass)': True, 'contains(flying)': False, 'contains(kong)': True, 'contains(rush)': False, 'contains(forces)': False, 'contains(charles)': False, 'contains(numerous)': False, 'contains(emotions)': False, 'contains(involves)': True, 'contains(patrick)': False, 'contains(weird)': False, 'contains(apparent)': False, 'contains(information)': False, 'contains(revenge)': False, 'contains(jay)': False, 'contains(toward)': False, 'contains(surprising)': False, 'contains(twice)': False, 'contains(editing)': False, 'contains(calls)': False, 'contains(lose)': False, 'contains(vegas)': False, 'contains(stage)': False, 'contains(intended)': False, 'contains(gags)': False, 'contains(opinion)': False, 'contains(likes)': False, 'contains(crazy)': False, 'contains(owner)': False, 'contains(places)': False, 'contains(pair)': False, 'contains(genuine)': False, 'contains(epic)': False, 'contains(speak)': False, 'contains(throw)': False, 'contains(appeal)': False, 'contains(gibson)': False, 'contains(captain)': False, 'contains(military)': False, 'contains(20)': False, 'contains(blair)': False, 'contains(nowhere)': False, 'contains(length)': False, 'contains(nicely)': False, 'contains(cause)': False, 'contains(pass)': False, 'contains(episode)': False, 'contains(kiss)': False, 'contains(arnold)': True, 'contains(please)': False, 'contains(hasn)': False, 'contains(phone)': False, 'contains(filmmaking)': False, 'contains(formula)': False, 'contains(boyfriend)': False, 'contains(talents)': False, 'contains(creating)': False, 'contains(kelly)': False, 'contains(buy)': False, 'contains(wide)': False, 'contains(fantasy)': False, 'contains(mood)': False, 'contains(heads)': False, 'contains(pathetic)': False, 'contains(lacks)': False, 'contains(loved)': False, 'contains(asked)': False, 'contains(mrs)': False, 'contains(witty)': False, 'contains(shakespeare)': False, 'contains(mulan)': False, 'contains(generation)': False, 'contains(affair)': False, 'contains(pieces)': False, 'contains(task)': False, 'contains(rare)': False, 'contains(kept)': False, 'contains(cameo)': False, 'contains(fascinating)': False, 'contains(ed)': False, 'contains(fbi)': False, 'contains(burton)': False, 'contains(incredible)': False, 'contains(accent)': False, 'contains(artist)': False, 'contains(superior)': False, 'contains(academy)': False, 'contains(thomas)': False, 'contains(spirit)': False, 'contains(technical)': False, 'contains(confusing)': False, 'contains(poorly)': False, 'contains(target)': False, 'contains(lover)': False, 'contains(woo)': False, 'contains(mentioned)': False, 'contains(theaters)': False, 'contains(plane)': False, 'contains(confused)': False, 'contains(dennis)': False, 'contains(rob)': False, 'contains(appropriate)': False, 'contains(christmas)': False, 'contains(considered)': False, 'contains(legend)': False, 'contains(shame)': False, 'contains(soul)': False, 'contains(matt)': False, 'contains(campbell)': False, 'contains(process)': False, 'contains(bottom)': False, 'contains(sitting)': False, 'contains(brain)': False, 'contains(creepy)': False, 'contains(13)': False, 'contains(forever)': False, 'contains(dude)': False, 'contains(crap)': False, 'contains(superb)': False, 'contains(speech)': False, 'contains(ice)': False, 'contains(journey)': False, 'contains(masterpiece)': False, 'contains(intriguing)': False, 'contains(names)': False, 'contains(pick)': False, 'contains(speaking)': False, 'contains(virtually)': False, 'contains(award)': False, 'contains(worthy)': False, 'contains(marriage)': False, 'contains(deliver)': False, 'contains(cash)': False, 'contains(magic)': False, 'contains(respect)': False, 'contains(product)': False, 'contains(necessary)': False, 'contains(suppose)': False, 'contains(silent)': False, 'contains(pointless)': False, 'contains(station)': False, 'contains(affleck)': False, 'contains(dimensional)': False, 'contains(charlie)': False, 'contains(allows)': False, 'contains(avoid)': False, 'contains(meant)': False, 'contains(cops)': False, 'contains(attitude)': False, 'contains(relationships)': False, 'contains(hits)': False, 'contains(stephen)': False, 'contains(spends)': False, 'contains(relief)': False, 'contains(physical)': True, 'contains(count)': False, 'contains(reviews)': False, 'contains(appreciate)': False, 'contains(cliches)': False, 'contains(holds)': False, 'contains(pure)': False, 'contains(plans)': False, 'contains(limited)': False, 'contains(failed)': False, 'contains(pain)': False, 'contains(impression)': False, 'contains(unless)': False, 'contains(sub)': False, 'contains([)': False, 'contains(total)': False, 'contains(creature)': False, 'contains(viewing)': False, 'contains(loves)': False, 'contains(princess)': False, 'contains(kate)': False, 'contains(rising)': False, 'contains(woods)': False, 'contains(baldwin)': False, 'contains(angry)': False, 'contains(drawn)': False, 'contains(step)': False, 'contains(matrix)': False, 'contains(themes)': False, 'contains(satire)': False, 'contains(arts)': False, 'contains(])': False, 'contains(remake)': False, 'contains(wall)': False, 'contains(moral)': False, 'contains(color)': False, 'contains(ray)': False, 'contains(stuck)': False, 'contains(touching)': False, 'contains(wit)': False, 'contains(tony)': False, 'contains(hanks)': False, 'contains(continues)': False, 'contains(damn)': False, 'contains(nobody)': False, 'contains(cartoon)': False, 'contains(keeping)': False, 'contains(realized)': False, 'contains(criminal)': False, 'contains(unfunny)': False, 'contains(comedic)': False, 'contains(martial)': False, 'contains(disappointing)': False, 'contains(anti)': False, 'contains(graphic)': False, 'contains(stunning)': False, 'contains(actions)': False, 'contains(floor)': False, 'contains(emotion)': False, 'contains(soldiers)': False, 'contains(edward)': False, 'contains(comedies)': False, 'contains(driver)': False, 'contains(expectations)': False, 'contains(added)': False, 'contains(mad)': False, 'contains(angels)': False, 'contains(shallow)': False, 'contains(suspect)': False, 'contains(humorous)': False, 'contains(phantom)': False, 'contains(appealing)': False, 'contains(device)': False, 'contains(design)': False, 'contains(industry)': False, 'contains(reach)': False, 'contains(fat)': False, 'contains(blame)': False, 'contains(united)': False, 'contains(sign)': False, 'contains(portrayal)': False, 'contains(rocky)': False, 'contains(finale)': False, 'contains(grand)': False, 'contains(opposite)': False, 'contains(hotel)': False, 'contains(match)': False, 'contains(damme)': False, 'contains(speed)': False, 'contains(ok)': False, 'contains(loving)': False, 'contains(field)': True, 'contains(larry)': False, 'contains(urban)': False, 'contains(troopers)': False, 'contains(compared)': False, 'contains(apes)': False, 'contains(rose)': False, 'contains(falling)': False, 'contains(era)': False, 'contains(loses)': False, 'contains(adults)': False, 'contains(managed)': False, 'contains(dad)': False, 'contains(therefore)': False, 'contains(pg)': False, 'contains(results)': False, 'contains(guns)': False, 'contains(radio)': False, 'contains(lady)': False, 'contains(manage)': False, 'contains(spice)': False, 'contains(naked)': False, 'contains(started)': False, 'contains(intense)': False, 'contains(humanity)': False, 'contains(wonderfully)': False, 'contains(slasher)': False, 'contains(bland)': False, 'contains(imagination)': False, 'contains(walking)': False, 'contains(willing)': False, 'contains(horse)': False, 'contains(rent)': False, 'contains(mix)': False, 'contains(generated)': False, 'contains(g)': False, 'contains(utterly)': False, 'contains(scientist)': False, 'contains(washington)': False, 'contains(notice)': False, 'contains(players)': False, 'contains(teenagers)': False, 'contains(moore)': False, 'contains(board)': False, 'contains(price)': False, 'contains(frightening)': False, 'contains(tommy)': False, 'contains(spectacular)': False, 'contains(bored)': False, 'contains(jane)': False, 'contains(join)': False, 'contains(producers)': False, 'contains(johnny)': False, 'contains(zero)': False, 'contains(vampires)': False, 'contains(adaptation)': False, 'contains(dollars)': False, 'contains(parody)': False, 'contains(documentary)': False, 'contains(dvd)': False, 'contains(wayne)': False, 'contains(post)': False, 'contains(exist)': False, 'contains(matters)': False, 'contains(chosen)': False, 'contains(mel)': False, 'contains(attractive)': True, 'contains(plain)': False, 'contains(trust)': False, 'contains(safe)': False, 'contains(reading)': False, 'contains(hoping)': False, 'contains(protagonist)': False, 'contains(feelings)': False, 'contains(fate)': False, 'contains(finding)': False, 'contains(feet)': False, 'contains(visuals)': False, 'contains(spawn)': False, 'contains(compelling)': False, 'contains(hall)': False, 'contains(sympathetic)': False, 'contains(featuring)': False, 'contains(difference)': False, 'contains(professional)': False, 'contains(drugs)': False, 'contains(ford)': False, 'contains(shooting)': False, 'contains(gold)': False, 'contains(patch)': False, 'contains(build)': False, 'contains(boat)': False, 'contains(cruise)': False, 'contains(honest)': False, 'contains(media)': False, 'contains(flicks)': False, 'contains(bug)': False, 'contains(bringing)': False, 'contains(dangerous)': True, 'contains(watched)': False, 'contains(grant)': False, 'contains(smile)': False, 'contains(plus)': False, 'contains(shouldn)': False, 'contains(decision)': False, 'contains(visually)': False, 'contains(allow)': False, 'contains(starship)': False, 'contains(roberts)': False, 'contains(dying)': False, 'contains(portrayed)': False, 'contains(turning)': False, 'contains(believes)': False, 'contains(changed)': False, 'contains(shock)': False, 'contains(destroy)': False, 'contains(30)': False, 'contains(crowd)': False, 'contains(broken)': False, 'contains(tired)': False, 'contains(fail)': False, 'contains(south)': False, 'contains(died)': False, 'contains(cult)': False, 'contains(fake)': False, 'contains(vincent)': False, 'contains(identity)': False, 'contains(sexy)': False, 'contains(hunt)': False, 'contains(jedi)': False, 'contains(flynt)': False, 'contains(alex)': False, 'contains(engaging)': False, 'contains(serve)': False, 'contains(snake)': False, 'contains(yeah)': False, 'contains(expecting)': False, 'contains(100)': False, 'contains(decade)': False, 'contains(ups)': False, 'contains(constant)': False, 'contains(current)': False, 'contains(survive)': False, 'contains(jimmy)': False, 'contains(buddy)': False, 'contains(send)': False, 'contains(brooks)': False, 'contains(goofy)': False, 'contains(likable)': False, 'contains(humour)': False, 'contains(technology)': False, 'contains(files)': False, 'contains(babe)': False, 'contains(aspects)': False, 'contains(presents)': False, 'contains(kills)': False, 'contains(supposedly)': False, 'contains(eight)': True, 'contains(sandler)': False, 'contains(hospital)': False, 'contains(test)': False, 'contains(hidden)': False, 'contains(brian)': False, 'contains(books)': False, 'contains(promise)': False, 'contains(determined)': False, 'contains(professor)': False, 'contains(welcome)': False, 'contains(pleasure)': False, 'contains(succeeds)': False, 'contains(individual)': False, 'contains(annie)': False, 'contains(mob)': False, 'contains(ted)': False, 'contains(virus)': False, 'contains(content)': False, 'contains(gary)': False, 'contains(direct)': False, 'contains(contrived)': False, 'contains(carpenter)': False, 'contains(scale)': False, 'contains(sick)': False, 'contains(nasty)': False, 'contains(conflict)': False, 'contains(haunting)': False, 'contains(ghost)': False, 'contains(filmmaker)': False, 'contains(japanese)': False, 'contains(helps)': False, 'contains(fare)': False, 'contains(lucky)': False, 'contains(ultimate)': False, 'contains(window)': False, 'contains(support)': False, 'contains(goal)': False, 'contains(provided)': False, 'contains(genius)': False, 'contains(winner)': False, 'contains(taylor)': False, 'contains(fantastic)': False, 'contains(faith)': False, 'contains(lynch)': False, 'contains(fit)': False, 'contains(catherine)': False, 'contains(ms)': False, 'contains(paced)': False, 'contains(breaks)': False, 'contains(al)': False, 'contains(frame)': False, 'contains(travel)': False, 'contains(badly)': False, 'contains(available)': False, 'contains(cares)': False, 'contains(reeves)': False, 'contains(crash)': False, 'contains(driving)': False, 'contains(press)': False, 'contains(seagal)': False, 'contains(amy)': False, 'contains(9)': False, 'contains(headed)': False, 'contains(instance)': False, 'contains(excuse)': False, 'contains(offensive)': False, 'contains(narrative)': False, 'contains(fault)': False, 'contains(bus)': False, 'contains(f)': False, 'contains(extreme)': False, 'contains(miller)': False, 'contains(guilty)': False, 'contains(grows)': False, 'contains(overly)': False, 'contains(liners)': False, 'contains(forgotten)': False, 'contains(ahead)': False, 'contains(accept)': False, 'contains(porn)': False, 'contains(directly)': False, 'contains(helen)': False, 'contains(began)': False, 'contains(lord)': False, 'contains(folks)': False, 'contains(mediocre)': False, 'contains(bar)': False, 'contains(surface)': False, 'contains(super)': False, 'contains(failure)': False, 'contains(6)': False, 'contains(acted)': False, 'contains(quiet)': False, 'contains(laughable)': False, 'contains(sheer)': False, 'contains(security)': True, 'contains(emotionally)': False, 'contains(season)': False, 'contains(stuart)': False, 'contains(jail)': True, 'contains(deals)': False, 'contains(cheesy)': False, 'contains(court)': False, 'contains(beach)': False, 'contains(austin)': False, 'contains(model)': False, 'contains(outstanding)': False, 'contains(substance)': False, 'contains(nudity)': False, 'contains(slapstick)': False, 'contains(joan)': False, 'contains(reveal)': False, 'contains(placed)': False, 'contains(check)': False, 'contains(beast)': False, 'contains(hurt)': False, 'contains(bloody)': False, 'contains(acts)': False, 'contains(fame)': False, 'contains(meeting)': False, 'contains(nuclear)': False, 'contains(1996)': False, 'contains(strength)': False, 'contains(center)': False, 'contains(funniest)': False, 'contains(standing)': True, 'contains(damon)': False, 'contains(clich)': False, 'contains(position)': False, 'contains(desire)': False, 'contains(driven)': False, 'contains(seat)': False, 'contains(stock)': False, 'contains(wondering)': True, 'contains(realizes)': False, 'contains(dealing)': False, 'contains(taste)': False, 'contains(routine)': False, 'contains(comparison)': False, 'contains(cinematographer)': False, 'contains(seconds)': False, 'contains(singing)': False, 'contains(gangster)': True, 'contains(responsible)': False, 'contains(football)': False, 'contains(remarkable)': False, 'contains(hunting)': False, 'contains(adams)': False, 'contains(fly)': False, 'contains(suspects)': False, 'contains(treat)': False, 'contains(hopes)': False, 'contains(heaven)': False, 'contains(myers)': False, 'contains(struggle)': False, 'contains(costumes)': False, 'contains(beat)': False, 'contains(happening)': False, 'contains(skills)': False, 'contains(ugly)': False, 'contains(figures)': False, 'contains(thoroughly)': False, 'contains(ill)': False, 'contains(surprises)': False, 'contains(player)': False, 'contains(rival)': False, 'contains(guard)': True, 'contains(anthony)': False, 'contains(strike)': False, 'contains(community)': False, 'contains(streets)': False, 'contains(hopkins)': False, 'contains(ended)': False, 'contains(originally)': False, 'contains(sarah)': False, 'contains(creative)': False, 'contains(characterization)': False, 'contains(thankfully)': False, 'contains(growing)': False, 'contains(sharp)': False, 'contains(williamson)': False, 'contains(eccentric)': False, 'contains(explained)': False, 'contains(hey)': False, 'contains(claire)': False, 'contains(steal)': False, 'contains(inevitable)': False, 'contains(joel)': False, 'contains(core)': False, 'contains(weren)': False, 'contains(sorry)': False, 'contains(built)': False, 'contains(anne)': False, 'contains(breaking)': False, 'contains(villains)': False, 'contains(critic)': False, 'contains(lets)': False, 'contains(visit)': False, 'contains(followed)': False}\n"
     ]
    }
   ],
   "source": [
    "print(document_features(movie_reviews.words('pos/cv957_8737.txt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8208d",
   "metadata": {},
   "source": [
    "Training and testing a classifier for document classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80415fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b76faffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f549ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7feb727e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3eee499c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "        contains(seagal) = True              neg : pos    =     12.5 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     10.9 : 1.0\n",
      "         contains(mulan) = True              pos : neg    =      8.9 : 1.0\n",
      "         contains(damon) = True              pos : neg    =      7.8 : 1.0\n",
      "   contains(wonderfully) = True              pos : neg    =      6.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fb351a",
   "metadata": {},
   "source": [
    "## 1.4   Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4084eb23",
   "metadata": {},
   "source": [
    "We can train a classifier to work out which **suffixes are most informative for POS tagging**. \n",
    "\n",
    "Let's begin by finding out what **the most common suffixes** are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "add0db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4b0baacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_fdist = nltk.FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4fa6fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in brown.words():\n",
    "    word = word.lower()\n",
    "    suffix_fdist[word[-1:]] += 1\n",
    "    suffix_fdist[word[-2:]] += 1\n",
    "    suffix_fdist[word[-3:]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "833034d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9b1e29d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', ',', '.', 's', 'd', 't', 'he', 'n', 'a', 'of', 'the', 'y', 'r', 'to', 'in', 'f', 'o', 'ed', 'nd', 'is', 'on', 'l', 'g', 'and', 'ng', 'er', 'as', 'ing', 'h', 'at', 'es', 'or', 're', 'it', '``', 'an', \"''\", 'm', ';', 'i', 'ly', 'ion', 'en', 'al', '?', 'nt', 'be', 'hat', 'st', 'his', 'th', 'll', 'le', 'ce', 'by', 'ts', 'me', 've', \"'\", 'se', 'ut', 'was', 'for', 'ent', 'ch', 'k', 'w', 'ld', '`', 'rs', 'ted', 'ere', 'her', 'ne', 'ns', 'ith', 'ad', 'ry', ')', '(', 'te', '--', 'ay', 'ty', 'ot', 'p', 'nce', \"'s\", 'ter', 'om', 'ss', ':', 'we', 'are', 'c', 'ers', 'uld', 'had', 'so', 'ey']\n"
     ]
    }
   ],
   "source": [
    "print(common_suffixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe33ad9a",
   "metadata": {},
   "source": [
    "Next, we'll define a feature extractor function which **checks a given word for these common suffixes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59f2fc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(word):\n",
    "    features = {}\n",
    "    for suffix in common_suffixes:\n",
    "        features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bc7119",
   "metadata": {},
   "source": [
    "Feature extraction functions behave like tinted glasses, highlighting some of the properties (colors) in our data and making it impossible to see other properties. 特征抽取器就像一个有色眼睛，只关注数据中的某些特性，忽略其他特性。\n",
    "\n",
    "The classifier will rely exclusively on these highlighted properties when determining how to label inputs. 分类器只依赖于这些被关注的特性来确定词性标签。\n",
    "\n",
    "In this case, the classifier will make its decisions based only on information about which of the common suffixes (if any) a given word has."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3828b1",
   "metadata": {},
   "source": [
    "Now that we've defined our feature extractor, we can use it to train a new \"decision tree\" classifier on Brown tagged corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41df8256",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_words = brown.tagged_words(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a3950ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(pos_features(n), g) for (n,g) in tagged_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aad128e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(featuresets) * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6da8492a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10055"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aed2421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[size:], featuresets[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6b7333c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此处训练特别慢，建议训练完成后，将模型保存到本地\n",
    "# classifier = nltk.DecisionTreeClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "76855682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "# with open('./pos_tree.pkl', \"wb\") as f:\n",
    "#     dill.dump(classifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9de8f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pos_tree.pkl','rb') as f:\n",
    "    classifier = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b4cde558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6270512182993535"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ae98362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NNS'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(pos_features('cats'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcabb79",
   "metadata": {},
   "source": [
    "One nice feature of decision tree models is that they are often **fairly easy to interpret** — we can even instruct NLTK to **print them out as pseudocode**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d048de11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if endswith(the) == False: \n",
      "  if endswith(,) == False: \n",
      "    if endswith(s) == False: \n",
      "      if endswith(.) == False: return '.'\n",
      "      if endswith(.) == True: return '.'\n",
      "    if endswith(s) == True: \n",
      "      if endswith(is) == False: return 'PP$'\n",
      "      if endswith(is) == True: return 'BEZ'\n",
      "  if endswith(,) == True: return ','\n",
      "if endswith(the) == True: return 'AT'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classifier.pseudocode(depth=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcfb5ed",
   "metadata": {},
   "source": [
    "The actual classifier **contains further nested if-then statements** below the ones shown here, but the `depth=4` argument just displays the top portion of the decision tree. (实际的分类器在此处显示的语句下方包含更多嵌套的 if-then 语句，但 depth=4 参数仅显示决策树的顶部。)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27436c9",
   "metadata": {},
   "source": [
    "## 1.5   Exploiting Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068760fa",
   "metadata": {},
   "source": [
    "By **augmenting the feature extraction function**, we could modify this part-of-speech tagger to leverage **a variety of other word-internal features**, such as the length of the word, the number of syllables it contains, or its prefix. \n",
    "\n",
    "However, as long as the feature extractor **just looks at the target word**, we **have no way to add features that depend on the context** that the word appears in. \n",
    "\n",
    "But **contextual features** often provide **powerful clues** about the correct tag.\n",
    "\n",
    "For example, when tagging the word \"fly\" knowing that the previous word is \"a\" will allow us to determine that it is functioning as a noun, not a verb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697e0154",
   "metadata": {},
   "source": [
    "We will revise the pattern that we used to define our feature extractor and pass in a complete (untagged) sentence, along with the index of the target word. \n",
    "\n",
    "The following codes employ a context-dependent feature extractor to define a part of speech tag classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "147749e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(sentence, i):\n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                \"suffix(2)\": sentence[i][-2:],\n",
    "                \"suffix(3)\": sentence[i][-3:]}\n",
    "    \n",
    "    # 在特征中增加target word的前一个词\n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1f44873a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'suffix(1)': 'n', 'suffix(2)': 'on', 'suffix(3)': 'ion', 'prev-word': 'an'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_features(brown.sents()[0], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "64c215ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sents = brown.tagged_sents(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "85e7c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "67e31083",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tagged_sent in tagged_sents:\n",
    "    untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "    for i, (word, tag) in enumerate(tagged_sent):\n",
    "        featuresets.append( (pos_features(untagged_sent, i), tag) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cd5bea61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7891596220785678"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c33da4",
   "metadata": {},
   "source": [
    "It is clear that exploiting contextual features improves the performance of our part-of-speech tagger.\n",
    "\n",
    "However, it is unable to **learn the generalization** that a word is probably a noun if it follows an adjective, because it **doesn't have access to the previous word's part-of-speech tag**.\n",
    "\n",
    "In general, simple classifiers always **treat each input as independent from all other inputs**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4158eda9",
   "metadata": {},
   "source": [
    "There are often cases, such as part-of-speech tagging, where we are interested in solving classification problems that are closely related to one another. (在某些情况下，例如词性标注，我们对解决彼此密切相关的分类问题感兴趣)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f826dd39",
   "metadata": {},
   "source": [
    "## 1.6   Sequence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f354b553",
   "metadata": {},
   "source": [
    "In order to capture **the dependencies between related classification tasks**, we can use **joint classifier models**, which choose an appropriate labeling for a collection of related inputs. \n",
    "\n",
    "In the case of part-of-speech tagging, a variety of different sequence classifier models can be used to **jointly choose part-of-speech tags for all the words in a given sentence**. (为给定句子中的所有单词联合地选择词性标注)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa859cd0",
   "metadata": {},
   "source": [
    "One sequence classification strategy, known as **consecutive classification** or **greedy sequence classification** (连续分类或贪婪序贯分类): \n",
    "\n",
    "- Find the most likely class label for the first input;\n",
    "\n",
    "- Use that answer to help find the best label for the next input.\n",
    "\n",
    "The process can then be repeated until all of the inputs have been labeled.\n",
    "\n",
    "The Bigram tagger in Chapter 5 has employed this strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751f71c4",
   "metadata": {},
   "source": [
    "First, we must augment our feature extractor function to **take a history argument**, which **provides a list of the tags that we've predicted for the sentence so far**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b49cb0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(sentence, i, history):\n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                 \"suffix(2)\": sentence[i][-2:],\n",
    "                 \"suffix(3)\": sentence[i][-3:]}\n",
    "    # 将target word的前一个词的pos tag作为特征\n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "        features[\"prev-tag\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "        features[\"prev-tag\"] = history[i-1]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df0b1ed",
   "metadata": {},
   "source": [
    "Having defined a feature extractor, we can proceed to build our sequence classifier.\n",
    "\n",
    "During training, we use the annotated tags to provide the appropriate history to the feature extractor, but when tagging new sentences, we generate the history list based on the output of the tagger itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "03872f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsecutivePosTagger(nltk.TaggerI):\n",
    "\n",
    "    def __init__(self, train_sents):\n",
    "        train_set = []\n",
    "        for tagged_sent in train_sents:\n",
    "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "            history = []\n",
    "            for i, (word, tag) in enumerate(tagged_sent):\n",
    "                featureset = pos_features(untagged_sent, i, history)\n",
    "                train_set.append( (featureset, tag) )\n",
    "                history.append(tag)\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    def tag(self, sentence):\n",
    "        history = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            featureset = pos_features(sentence, i, history)\n",
    "            tag = self.classifier.classify(featureset)\n",
    "            history.append(tag)\n",
    "        return zip(sentence, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "34fcd5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sents = brown.tagged_sents(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fc93a755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7980528511821975\n"
     ]
    }
   ],
   "source": [
    "size = int(len(tagged_sents) * 0.1)\n",
    "train_sents, test_sents = tagged_sents[size:], tagged_sents[:size]\n",
    "tagger = ConsecutivePosTagger(train_sents)\n",
    "print(tagger.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e075b6",
   "metadata": {},
   "source": [
    "## 1.7   Other Methods for Sequence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a9990",
   "metadata": {},
   "source": [
    "One shortcoming of this approach is that we commit to every decision that we make. (为每个决策做出承诺)\n",
    "\n",
    "For example, if we decide to label a word as a noun, but later find evidence that it should have been a verb, there's **no way to go back and fix our mistake**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba0ac07",
   "metadata": {},
   "source": [
    "One solution to this problem is to adopt a **transformational strategy** instead. \n",
    "\n",
    "Transformational joint classifiers work by creating an initial assignment of labels for the inputs, and then iteratively refining that assignment in an attempt to repair inconsistencies between related inputs. (先给定一个初始的标签序列，然后迭代地修正)\n",
    "\n",
    "The **Brill tagger**, described in Chapter 5, is a good example of this strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bebc5a2",
   "metadata": {},
   "source": [
    "Another solution is to **assign scores to all of the possible sequences of part-of-speech tags**, and to **choose the sequence whose overall score is highest**. Such as Hidden Markov Models, Maximum Entropy Markov Models and Linear-Chain Conditional Random Field Models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ea7ab6",
   "metadata": {},
   "source": [
    "# 2.   Further Examples of Supervised Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f920fd6e",
   "metadata": {},
   "source": [
    "## 2.1   Sentence Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7771ba",
   "metadata": {},
   "source": [
    "Sentence segmentation can be viewed as a classification task for punctuation: whenever we encounter a symbol that could possibly end a sentence, such as a period or a question mark, we have to decide whether it terminates the preceding sentence. (标点分类问题)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa10293e",
   "metadata": {},
   "source": [
    "The first step is to obtain some data that **has already been segmented into sentences** and **convert it into a form that is suitable for extracting features**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "65606518",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = nltk.corpus.treebank_raw.sents()\n",
    "tokens = []\n",
    "boundaries = set()\n",
    "offset = 0\n",
    "for sent in sents:\n",
    "    tokens.extend(sent)\n",
    "    offset += len(sent)\n",
    "    boundaries.add(offset-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7406780f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'START', 'Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov', '.', '29', '.', 'Mr', '.', 'Vinken', 'is', 'chairman', 'of', 'Elsevier', 'N', '.', 'V', '.,', 'the', 'Dutch', 'publishing', 'group', '.', '.', 'START', 'Rudolph']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "326ca973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 20,\n",
       " 36,\n",
       " 38,\n",
       " 64,\n",
       " 66,\n",
       " 102,\n",
       " 134,\n",
       " 163,\n",
       " 199,\n",
       " 211,\n",
       " 228,\n",
       " 237,\n",
       " 258,\n",
       " 286,\n",
       " 310,\n",
       " 344,\n",
       " 365,\n",
       " 387,\n",
       " 406,\n",
       " 429,\n",
       " 453,\n",
       " 489,\n",
       " 512,\n",
       " 558,\n",
       " 617,\n",
       " 637,\n",
       " 655,\n",
       " 671,\n",
       " 692,\n",
       " 705,\n",
       " 739,\n",
       " 763,\n",
       " 796,\n",
       " 811,\n",
       " 821,\n",
       " 823,\n",
       " 846,\n",
       " 891,\n",
       " 907,\n",
       " 934,\n",
       " 958,\n",
       " 976,\n",
       " 1013,\n",
       " 1048,\n",
       " 1077,\n",
       " 1092,\n",
       " 1117,\n",
       " 1142,\n",
       " 1153,\n",
       " 1192,\n",
       " 1213,\n",
       " 1235,\n",
       " 1273,\n",
       " 1275,\n",
       " 1312,\n",
       " 1332,\n",
       " 1348,\n",
       " 1350,\n",
       " 1378,\n",
       " 1398,\n",
       " 1400,\n",
       " 1424,\n",
       " 1431,\n",
       " 1448,\n",
       " 1463,\n",
       " 1479,\n",
       " 1481,\n",
       " 1505,\n",
       " 1529,\n",
       " 1552,\n",
       " 1570,\n",
       " 1601,\n",
       " 1624,\n",
       " 1626,\n",
       " 1656,\n",
       " 1679,\n",
       " 1702,\n",
       " 1716,\n",
       " 1718,\n",
       " 1751,\n",
       " 1755,\n",
       " 1773,\n",
       " 1791,\n",
       " 1832,\n",
       " 1863,\n",
       " 1892,\n",
       " 1897,\n",
       " 1926,\n",
       " 1943,\n",
       " 1962,\n",
       " 1993,\n",
       " 2009,\n",
       " 2032,\n",
       " 2051,\n",
       " 2065,\n",
       " 2103,\n",
       " 2125,\n",
       " 2148,\n",
       " 2166,\n",
       " 2168,\n",
       " 2196,\n",
       " 2231,\n",
       " 2272,\n",
       " 2299,\n",
       " 2320,\n",
       " 2341,\n",
       " 2368,\n",
       " 2380,\n",
       " 2382,\n",
       " 2411,\n",
       " 2440,\n",
       " 2492,\n",
       " 2513,\n",
       " 2529,\n",
       " 2585,\n",
       " 2599,\n",
       " 2620,\n",
       " 2659,\n",
       " 2712,\n",
       " 2739,\n",
       " 2769,\n",
       " 2782,\n",
       " 2812,\n",
       " 2838,\n",
       " 2861,\n",
       " 2863,\n",
       " 2903,\n",
       " 2946,\n",
       " 2997,\n",
       " 3040,\n",
       " 3096,\n",
       " 3125,\n",
       " 3134,\n",
       " 3148,\n",
       " 3177,\n",
       " 3182,\n",
       " 3183,\n",
       " 3184,\n",
       " 3211,\n",
       " 3245,\n",
       " 3288,\n",
       " 3299,\n",
       " 3326,\n",
       " 3365,\n",
       " 3390,\n",
       " 3392,\n",
       " 3438,\n",
       " 3472,\n",
       " 3474,\n",
       " 3505,\n",
       " 3539,\n",
       " 3582,\n",
       " 3613,\n",
       " 3618,\n",
       " 3619,\n",
       " 3620,\n",
       " 3635,\n",
       " 3656,\n",
       " 3680,\n",
       " 3701,\n",
       " 3723,\n",
       " 3754,\n",
       " 3778,\n",
       " 3797,\n",
       " 3824,\n",
       " 3846,\n",
       " 3867,\n",
       " 3893,\n",
       " 3925,\n",
       " 3944,\n",
       " 3959,\n",
       " 3989,\n",
       " 4020,\n",
       " 4037,\n",
       " 4052,\n",
       " 4074,\n",
       " 4076,\n",
       " 4116,\n",
       " 4137,\n",
       " 4149,\n",
       " 4164,\n",
       " 4181,\n",
       " 4217,\n",
       " 4219,\n",
       " 4244,\n",
       " 4275,\n",
       " 4289,\n",
       " 4291,\n",
       " 4327,\n",
       " 4352,\n",
       " 4402,\n",
       " 4446,\n",
       " 4472,\n",
       " 4508,\n",
       " 4535,\n",
       " 4560,\n",
       " 4575,\n",
       " 4595,\n",
       " 4609,\n",
       " 4641,\n",
       " 4676,\n",
       " 4702,\n",
       " 4714,\n",
       " 4729,\n",
       " 4760,\n",
       " 4788,\n",
       " 4809,\n",
       " 4860,\n",
       " 4888,\n",
       " 4921,\n",
       " 4956,\n",
       " 4966,\n",
       " 4980,\n",
       " 4989,\n",
       " 5007,\n",
       " 5045,\n",
       " 5059,\n",
       " 5102,\n",
       " 5125,\n",
       " 5162,\n",
       " 5185,\n",
       " 5198,\n",
       " 5260,\n",
       " 5266,\n",
       " 5289,\n",
       " 5291,\n",
       " 5315,\n",
       " 5330,\n",
       " 5345,\n",
       " 5361,\n",
       " 5376,\n",
       " 5396,\n",
       " 5405,\n",
       " 5421,\n",
       " 5427,\n",
       " 5429,\n",
       " 5478,\n",
       " 5522,\n",
       " 5560,\n",
       " 5588,\n",
       " 5629,\n",
       " 5677,\n",
       " 5708,\n",
       " 5727,\n",
       " 5764,\n",
       " 5788,\n",
       " 5826,\n",
       " 5839,\n",
       " 5854,\n",
       " 5903,\n",
       " 5957,\n",
       " 5976,\n",
       " 6004,\n",
       " 6030,\n",
       " 6063,\n",
       " 6085,\n",
       " 6116,\n",
       " 6118,\n",
       " 6144,\n",
       " 6173,\n",
       " 6189,\n",
       " 6218,\n",
       " 6235,\n",
       " 6252,\n",
       " 6290,\n",
       " 6305,\n",
       " 6307,\n",
       " 6333,\n",
       " 6347,\n",
       " 6364,\n",
       " 6374,\n",
       " 6395,\n",
       " 6427,\n",
       " 6441,\n",
       " 6462,\n",
       " 6473,\n",
       " 6510,\n",
       " 6530,\n",
       " 6537,\n",
       " 6572,\n",
       " 6594,\n",
       " 6622,\n",
       " 6648,\n",
       " 6664,\n",
       " 6666,\n",
       " 6670,\n",
       " 6694,\n",
       " 6711,\n",
       " 6733,\n",
       " 6762,\n",
       " 6764,\n",
       " 6815,\n",
       " 6834,\n",
       " 6842,\n",
       " 6851,\n",
       " 6867,\n",
       " 6876,\n",
       " 6887,\n",
       " 6911,\n",
       " 6939,\n",
       " 6941,\n",
       " 6945,\n",
       " 6983,\n",
       " 6991,\n",
       " 7025,\n",
       " 7037,\n",
       " 7039,\n",
       " 7085,\n",
       " 7116,\n",
       " 7128,\n",
       " 7152,\n",
       " 7203,\n",
       " 7243,\n",
       " 7266,\n",
       " 7327,\n",
       " 7329,\n",
       " 7367,\n",
       " 7397,\n",
       " 7411,\n",
       " 7433,\n",
       " 7454,\n",
       " 7492,\n",
       " 7515,\n",
       " 7546,\n",
       " 7563,\n",
       " 7573,\n",
       " 7595,\n",
       " 7607,\n",
       " 7627,\n",
       " 7629,\n",
       " 7655,\n",
       " 7657,\n",
       " 7689,\n",
       " 7725,\n",
       " 7741,\n",
       " 7752,\n",
       " 7773,\n",
       " 7788,\n",
       " 7816,\n",
       " 7856,\n",
       " 7894,\n",
       " 7912,\n",
       " 7941,\n",
       " 7977,\n",
       " 8020,\n",
       " 8022,\n",
       " 8052,\n",
       " 8054,\n",
       " 8094,\n",
       " 8128,\n",
       " 8130,\n",
       " 8138,\n",
       " 8182,\n",
       " 8207,\n",
       " 8221,\n",
       " 8236,\n",
       " 8238,\n",
       " 8276,\n",
       " 8285,\n",
       " 8319,\n",
       " 8346,\n",
       " 8348,\n",
       " 8355,\n",
       " 8390,\n",
       " 8430,\n",
       " 8442,\n",
       " 8481,\n",
       " 8485,\n",
       " 8498,\n",
       " 8514,\n",
       " 8535,\n",
       " 8546,\n",
       " 8555,\n",
       " 8589,\n",
       " 8613,\n",
       " 8625,\n",
       " 8662,\n",
       " 8673,\n",
       " 8702,\n",
       " 8716,\n",
       " 8732,\n",
       " 8752,\n",
       " 8775,\n",
       " 8786,\n",
       " 8795,\n",
       " 8812,\n",
       " 8841,\n",
       " 8856,\n",
       " 8885,\n",
       " 8916,\n",
       " 8940,\n",
       " 8971,\n",
       " 8990,\n",
       " 9013,\n",
       " 9033,\n",
       " 9054,\n",
       " 9073,\n",
       " 9103,\n",
       " 9122,\n",
       " 9146,\n",
       " 9198,\n",
       " 9216,\n",
       " 9245,\n",
       " 9247,\n",
       " 9288,\n",
       " 9311,\n",
       " 9340,\n",
       " 9362,\n",
       " 9380,\n",
       " 9423,\n",
       " 9471,\n",
       " 9485,\n",
       " 9504,\n",
       " 9522,\n",
       " 9562,\n",
       " 9564,\n",
       " 9595,\n",
       " 9621,\n",
       " 9638,\n",
       " 9651,\n",
       " 9671,\n",
       " 9701,\n",
       " 9728,\n",
       " 9764,\n",
       " 9777,\n",
       " 9801,\n",
       " 9826,\n",
       " 9848,\n",
       " 9860,\n",
       " 9863,\n",
       " 9869,\n",
       " 9889,\n",
       " 9895,\n",
       " 9908,\n",
       " 9925,\n",
       " 9942,\n",
       " 9953,\n",
       " 9971,\n",
       " 10004,\n",
       " 10043,\n",
       " 10059,\n",
       " 10099,\n",
       " 10125,\n",
       " 10142,\n",
       " 10164,\n",
       " 10177,\n",
       " 10207,\n",
       " 10217,\n",
       " 10259,\n",
       " 10293,\n",
       " 10321,\n",
       " 10334,\n",
       " 10352,\n",
       " 10375,\n",
       " 10403,\n",
       " 10406,\n",
       " 10419,\n",
       " 10436,\n",
       " 10450,\n",
       " 10498,\n",
       " 10523,\n",
       " 10544,\n",
       " 10565,\n",
       " 10584,\n",
       " 10598,\n",
       " 10615,\n",
       " 10624,\n",
       " 10647,\n",
       " 10658,\n",
       " 10676,\n",
       " 10693,\n",
       " 10721,\n",
       " 10734,\n",
       " 10764,\n",
       " 10803,\n",
       " 10827,\n",
       " 10845,\n",
       " 10866,\n",
       " 10895,\n",
       " 10905,\n",
       " 10926,\n",
       " 10945,\n",
       " 10947,\n",
       " 10987,\n",
       " 11005,\n",
       " 11023,\n",
       " 11034,\n",
       " 11052,\n",
       " 11056,\n",
       " 11088,\n",
       " 11130,\n",
       " 11161,\n",
       " 11183,\n",
       " 11191,\n",
       " 11233,\n",
       " 11253,\n",
       " 11292,\n",
       " 11308,\n",
       " 11344,\n",
       " 11371,\n",
       " 11388,\n",
       " 11432,\n",
       " 11457,\n",
       " 11477,\n",
       " 11495,\n",
       " 11520,\n",
       " 11610,\n",
       " 11636,\n",
       " 11669,\n",
       " 11691,\n",
       " 11724,\n",
       " 11782,\n",
       " 11795,\n",
       " 11858,\n",
       " 11890,\n",
       " 11928,\n",
       " 11939,\n",
       " 11961,\n",
       " 11981,\n",
       " 11995,\n",
       " 12024,\n",
       " 12050,\n",
       " 12070,\n",
       " 12116,\n",
       " 12122,\n",
       " 12144,\n",
       " 12160,\n",
       " 12184,\n",
       " 12224,\n",
       " 12294,\n",
       " 12330,\n",
       " 12370,\n",
       " 12391,\n",
       " 12424,\n",
       " 12450,\n",
       " 12481,\n",
       " 12506,\n",
       " 12528,\n",
       " 12560,\n",
       " 12584,\n",
       " 12599,\n",
       " 12629,\n",
       " 12657,\n",
       " 12681,\n",
       " 12703,\n",
       " 12736,\n",
       " 12759,\n",
       " 12778,\n",
       " 12795,\n",
       " 12819,\n",
       " 12833,\n",
       " 12834,\n",
       " 12835,\n",
       " 12875,\n",
       " 12906,\n",
       " 12908,\n",
       " 12951,\n",
       " 12987,\n",
       " 12996,\n",
       " 13027,\n",
       " 13050,\n",
       " 13065,\n",
       " 13067,\n",
       " 13085,\n",
       " 13095,\n",
       " 13126,\n",
       " 13176,\n",
       " 13212,\n",
       " 13234,\n",
       " 13244,\n",
       " 13263,\n",
       " 13318,\n",
       " 13360,\n",
       " 13382,\n",
       " 13403,\n",
       " 13429,\n",
       " 13465,\n",
       " 13471,\n",
       " 13484,\n",
       " 13496,\n",
       " 13511,\n",
       " 13517,\n",
       " 13566,\n",
       " 13579,\n",
       " 13601,\n",
       " 13625,\n",
       " 13668,\n",
       " 13695,\n",
       " 13714,\n",
       " 13735,\n",
       " 13764,\n",
       " 13784,\n",
       " 13815,\n",
       " 13852,\n",
       " 13881,\n",
       " 13895,\n",
       " 13919,\n",
       " 13932,\n",
       " 13939,\n",
       " 13968,\n",
       " 14003,\n",
       " 14016,\n",
       " 14039,\n",
       " 14062,\n",
       " 14105,\n",
       " 14130,\n",
       " 14132,\n",
       " 14162,\n",
       " 14202,\n",
       " 14224,\n",
       " 14247,\n",
       " 14268,\n",
       " 14270,\n",
       " 14293,\n",
       " 14334,\n",
       " 14378,\n",
       " 14403,\n",
       " 14440,\n",
       " 14480,\n",
       " 14502,\n",
       " 14524,\n",
       " 14554,\n",
       " 14581,\n",
       " 14601,\n",
       " 14635,\n",
       " 14680,\n",
       " 14700,\n",
       " 14732,\n",
       " 14761,\n",
       " 14775,\n",
       " 14786,\n",
       " 14799,\n",
       " 14811,\n",
       " 14820,\n",
       " 14832,\n",
       " 14849,\n",
       " 14856,\n",
       " 14861,\n",
       " 14878,\n",
       " 14912,\n",
       " 14935,\n",
       " 14963,\n",
       " 14974,\n",
       " 15007,\n",
       " 15029,\n",
       " 15048,\n",
       " 15072,\n",
       " 15097,\n",
       " 15104,\n",
       " 15135,\n",
       " 15167,\n",
       " 15212,\n",
       " 15265,\n",
       " 15310,\n",
       " 15337,\n",
       " 15355,\n",
       " 15390,\n",
       " 15414,\n",
       " 15444,\n",
       " 15473,\n",
       " 15505,\n",
       " 15543,\n",
       " 15570,\n",
       " 15598,\n",
       " 15635,\n",
       " 15639,\n",
       " 15644,\n",
       " 15649,\n",
       " 15669,\n",
       " 15707,\n",
       " 15719,\n",
       " 15757,\n",
       " 15770,\n",
       " 15777,\n",
       " 15782,\n",
       " 15803,\n",
       " 15804,\n",
       " 15805,\n",
       " 15817,\n",
       " 15833,\n",
       " 15840,\n",
       " 15872,\n",
       " 15900,\n",
       " 15927,\n",
       " 15937,\n",
       " 15958,\n",
       " 15986,\n",
       " 15988,\n",
       " 16016,\n",
       " 16036,\n",
       " 16059,\n",
       " 16061,\n",
       " 16074,\n",
       " 16108,\n",
       " 16128,\n",
       " 16166,\n",
       " 16187,\n",
       " 16225,\n",
       " 16242,\n",
       " 16263,\n",
       " 16285,\n",
       " 16318,\n",
       " 16337,\n",
       " 16367,\n",
       " 16389,\n",
       " 16396,\n",
       " 16430,\n",
       " 16445,\n",
       " 16459,\n",
       " 16487,\n",
       " 16502,\n",
       " 16554,\n",
       " 16568,\n",
       " 16587,\n",
       " 16622,\n",
       " 16650,\n",
       " 16680,\n",
       " 16698,\n",
       " 16731,\n",
       " 16777,\n",
       " 16822,\n",
       " 16841,\n",
       " 16861,\n",
       " 16882,\n",
       " 16902,\n",
       " 16942,\n",
       " 16973,\n",
       " 16998,\n",
       " 17036,\n",
       " 17057,\n",
       " 17087,\n",
       " 17125,\n",
       " 17142,\n",
       " 17165,\n",
       " 17193,\n",
       " 17226,\n",
       " 17228,\n",
       " 17236,\n",
       " 17264,\n",
       " 17276,\n",
       " 17290,\n",
       " 17291,\n",
       " 17292,\n",
       " 17293,\n",
       " 17306,\n",
       " 17307,\n",
       " 17308,\n",
       " 17309,\n",
       " 17331,\n",
       " 17356,\n",
       " 17375,\n",
       " 17387,\n",
       " 17407,\n",
       " 17431,\n",
       " 17457,\n",
       " 17476,\n",
       " 17499,\n",
       " 17512,\n",
       " 17520,\n",
       " 17529,\n",
       " 17549,\n",
       " 17621,\n",
       " 17658,\n",
       " 17680,\n",
       " 17705,\n",
       " 17719,\n",
       " 17748,\n",
       " 17761,\n",
       " 17781,\n",
       " 17819,\n",
       " 17849,\n",
       " 17865,\n",
       " 17890,\n",
       " 17907,\n",
       " 17920,\n",
       " 17956,\n",
       " 17991,\n",
       " 18014,\n",
       " 18037,\n",
       " 18072,\n",
       " 18106,\n",
       " 18115,\n",
       " 18168,\n",
       " 18184,\n",
       " 18203,\n",
       " 18247,\n",
       " 18282,\n",
       " 18310,\n",
       " 18324,\n",
       " 18375,\n",
       " 18394,\n",
       " 18417,\n",
       " 18436,\n",
       " 18455,\n",
       " 18463,\n",
       " 18482,\n",
       " 18533,\n",
       " 18565,\n",
       " 18587,\n",
       " 18611,\n",
       " 18640,\n",
       " 18649,\n",
       " 18663,\n",
       " 18692,\n",
       " 18713,\n",
       " 18749,\n",
       " 18792,\n",
       " 18831,\n",
       " 18853,\n",
       " 18874,\n",
       " 18900,\n",
       " 18934,\n",
       " 18957,\n",
       " 18975,\n",
       " 18991,\n",
       " 19009,\n",
       " 19025,\n",
       " 19030,\n",
       " 19039,\n",
       " 19059,\n",
       " 19082,\n",
       " 19095,\n",
       " 19131,\n",
       " 19151,\n",
       " 19174,\n",
       " 19211,\n",
       " 19229,\n",
       " 19268,\n",
       " 19297,\n",
       " 19313,\n",
       " 19329,\n",
       " 19340,\n",
       " 19354,\n",
       " 19391,\n",
       " 19421,\n",
       " 19431,\n",
       " 19447,\n",
       " 19462,\n",
       " 19474,\n",
       " 19485,\n",
       " 19521,\n",
       " 19562,\n",
       " 19588,\n",
       " 19607,\n",
       " 19616,\n",
       " 19621,\n",
       " 19625,\n",
       " 19631,\n",
       " 19643,\n",
       " 19656,\n",
       " 19683,\n",
       " 19703,\n",
       " 19708,\n",
       " 19726,\n",
       " 19735,\n",
       " 19747,\n",
       " 19779,\n",
       " 19805,\n",
       " 19827,\n",
       " 19855,\n",
       " 19900,\n",
       " 19925,\n",
       " 19937,\n",
       " 19977,\n",
       " 19990,\n",
       " 20000,\n",
       " 20019,\n",
       " 20046,\n",
       " 20073,\n",
       " 20088,\n",
       " 20097,\n",
       " 20116,\n",
       " 20142,\n",
       " 20165,\n",
       " 20186,\n",
       " 20195,\n",
       " 20224,\n",
       " 20234,\n",
       " 20272,\n",
       " 20274,\n",
       " 20293,\n",
       " 20323,\n",
       " 20348,\n",
       " 20362,\n",
       " 20394,\n",
       " 20412,\n",
       " 20458,\n",
       " 20474,\n",
       " 20488,\n",
       " 20512,\n",
       " 20562,\n",
       " 20585,\n",
       " 20654,\n",
       " 20677,\n",
       " 20726,\n",
       " 20747,\n",
       " 20774,\n",
       " 20811,\n",
       " 20832,\n",
       " 20842,\n",
       " 20855,\n",
       " 20888,\n",
       " 20899,\n",
       " 20913,\n",
       " 20964,\n",
       " 20998,\n",
       " 21067,\n",
       " 21079,\n",
       " 21087,\n",
       " 21131,\n",
       " 21154,\n",
       " 21186,\n",
       " 21212,\n",
       " 21229,\n",
       " 21235,\n",
       " 21268,\n",
       " 21294,\n",
       " 21317,\n",
       " 21319,\n",
       " 21339,\n",
       " 21350,\n",
       " 21382,\n",
       " 21395,\n",
       " 21403,\n",
       " 21405,\n",
       " 21428,\n",
       " 21463,\n",
       " 21491,\n",
       " 21517,\n",
       " 21545,\n",
       " 21584,\n",
       " 21615,\n",
       " 21661,\n",
       " 21681,\n",
       " 21720,\n",
       " 21750,\n",
       " 21774,\n",
       " 21798,\n",
       " 21815,\n",
       " 21832,\n",
       " 21870,\n",
       " 21887,\n",
       " 21923,\n",
       " 21951,\n",
       " 21969,\n",
       " 21986,\n",
       " 22024,\n",
       " 22045,\n",
       " 22091,\n",
       " 22116,\n",
       " 22118,\n",
       " 22153,\n",
       " 22175,\n",
       " 22188,\n",
       " 22208,\n",
       " 22228,\n",
       " 22246,\n",
       " 22269,\n",
       " 22290,\n",
       " 22328,\n",
       " 22335,\n",
       " 22351,\n",
       " 22394,\n",
       " 22421,\n",
       " 22457,\n",
       " 22473,\n",
       " 22509,\n",
       " 22536,\n",
       " 22555,\n",
       " 22574,\n",
       " 22585,\n",
       " 22624,\n",
       " 22659,\n",
       " 22693,\n",
       " 22720,\n",
       " 22744,\n",
       " 22793,\n",
       " 22823,\n",
       " 22834,\n",
       " 22864,\n",
       " 22899,\n",
       " 22933,\n",
       " 22960,\n",
       " 22979,\n",
       " 23005,\n",
       " 23048,\n",
       " 23062,\n",
       " 23079,\n",
       " 23112,\n",
       " 23172,\n",
       " 23188,\n",
       " 23216,\n",
       " 23249,\n",
       " 23251,\n",
       " 23281,\n",
       " 23325,\n",
       " 23378,\n",
       " 23407,\n",
       " 23440,\n",
       " ...]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(boundaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182b3826",
   "metadata": {},
   "source": [
    "Next, we need to specify the features of the data that will be used in order to decide whether punctuation indicates a sentence-boundary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a3db42ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punct_features(tokens, i):\n",
    "    return {'next-word-capitalized': tokens[i+1][0].isupper(),\n",
    "            'prev-word': tokens[i-1].lower(),\n",
    "            'punct': tokens[i],\n",
    "            'prev-word-is-one-char': len(tokens[i-1]) == 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6784c5d1",
   "metadata": {},
   "source": [
    "Based on this feature extractor, we can create a list of labeled featuresets by selecting all the punctuation tokens, and tagging whether they are boundary tokens or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "acf48848",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(punct_features(tokens, i), (i in boundaries))\n",
    "               for i in range(1, len(tokens)-1)\n",
    "               if tokens[i] in '.?!']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb567267",
   "metadata": {},
   "source": [
    "Using these featuresets, we can train and evaluate a punctuation classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7a700535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936026936026936"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8871f706",
   "metadata": {},
   "source": [
    "To **use this classifier to perform sentence segmentation**, we simply check each punctuation mark to see whether it's labeled as a boundary; and **divide the list of words at the boundary marks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3bdf9f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_sentences(words):\n",
    "    start = 0\n",
    "    sents = []\n",
    "    for i, word in enumerate(words):\n",
    "        if word in '.?!' and classifier.classify(punct_features(words, i)) == True:\n",
    "            sents.append(words[start:i+1])\n",
    "            start = i+1\n",
    "    if start < len(words):\n",
    "        sents.append(words[start:])\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5584ee3e",
   "metadata": {},
   "source": [
    "## 2.2   Identifying Dialogue Act Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aa32e7",
   "metadata": {},
   "source": [
    "When processing dialogue, it can be useful to **think of utterances as a type of action performed by the speaker**. (将话语视为说话者执行的一种动作)\n",
    "\n",
    "**Greetings, questions, answers, assertions, and clarifications** 问候、问题、答案、断言和澄清() can all be thought of as types of speech-based actions. \n",
    "\n",
    "**Recognizing the dialogue acts underlying the utterances** in a dialogue can be an important first step in **understanding the conversation**. (识别对话行为/意图是理解对话的重要步骤/首要步骤)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a681b3",
   "metadata": {},
   "source": [
    "The NPS Chat Corpus consists of over 10,000 posts from instant messaging sessions.\n",
    "\n",
    "These posts have all been labeled with one of 15 dialogue act types, such as \"Statement,\" \"Emotion,\" \"ynQuestion\", and \"Continuer.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2a667217",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = nltk.corpus.nps_chat.xml_posts()[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "41071629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.collections.LazySubsequence"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24695d23",
   "metadata": {},
   "source": [
    "Next, we'll define a simple feature extractor that checks what words the post contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "46180282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dialogue_act_features(post):\n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(post):\n",
    "        features['contains({})'.format(word.lower())] = True\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0731c7",
   "metadata": {},
   "source": [
    "Finally, we construct the training and testing data by applying the feature extractor to each post (using `post.get('class')` to get a post's dialogue act type), and create a new classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "362dedcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.667\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(dialogue_act_features(post.text), post.get('class'))\n",
    "               for post in posts]\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918f40e",
   "metadata": {},
   "source": [
    "## 2.3   Recognizing Textual Entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed8b6c",
   "metadata": {},
   "source": [
    "Recognizing textual entailment (RTE) is the task of determining whether a given piece of text T entails another text called the \"hypothesis\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e202b4",
   "metadata": {},
   "source": [
    "**T**: Parviz Davudi was representing Iran at a meeting of the Shanghai Co-operation Organisation (SCO), the fledgling association that binds Russia, China and four former Soviet republics of central Asia together to fight terrorism. (Parviz Davudi 代表伊朗出席了上海合作组织 (SCO) 的会议，该组织是一个将俄罗斯、中国和四个前苏联中亚共和国联合起来打击恐怖主义的新兴组织。)\n",
    "\n",
    "**H**: China is a member of SCO. (中国是上合组织成员国)\n",
    "\n",
    "**TRUE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3499c068",
   "metadata": {},
   "source": [
    "**T**: According to NC Articles of Organization, the members of LLC company are H. Nelson Beavers, III, H. Chester Beavers and Jennie Beavers Stewart. (根据 NC 组织章程，LLC 公司的成员是 H. Nelson Beavers, III, H. Chester Beavers 和 Jennie Beavers Stewart)\n",
    "\n",
    "**H**: Jennie Beavers Stewart is a share-holder of Carolina Analytical Laboratory. (Jennie Beavers Stewart 是 Carolina Analytical Laboratory 的股东)\n",
    "\n",
    "**FALSE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53f3aa4",
   "metadata": {},
   "source": [
    "We can treat RTE as a classification task, in which we try to predict the True/False label for each pair. \n",
    "\n",
    "Although it seems likely that successful approaches to this task will involve a combination of parsing, semantics and real world knowledge.\n",
    "\n",
    "Many early attempts at RTE achieved reasonably good results with shallow analysis, based on **similarity between the text and hypothesis at the word level**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a4d35",
   "metadata": {},
   "source": [
    "If there is an entailment, then all the information expressed by the hypothesis should also be present in the text. \n",
    "\n",
    "Conversely, if **there is information found in the hypothesis that is absent from the text**, then there will be no entailment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca6863f",
   "metadata": {},
   "source": [
    "In our RTE feature detector below, we let **words serve as proxies for information**, and our features count **the degree of word overlap**, and the degree to which **there are words in the hypothesis but not in the text** (captured by the method `hyp_extra()`).\n",
    "\n",
    "**Not all words are equally important** — **Named Entity mentions** such as the names of people, organizations and places are likely to be **more significant**, which motivates us to extract distinct information for words and nes (Named Entities). \n",
    "\n",
    "In addition, some **high frequency function words** are filtered out as \"**stopwords**\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "93e82b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rte_features(rtepair):\n",
    "    extractor = nltk.RTEFeatureExtractor(rtepair)\n",
    "    features = {}\n",
    "    features['word_overlap'] = len(extractor.overlap('word'))\n",
    "    features['word_hyp_extra'] = len(extractor.hyp_extra('word'))\n",
    "    features['ne_overlap'] = len(extractor.overlap('ne'))\n",
    "    features['ne_hyp_extra'] = len(extractor.hyp_extra('ne'))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ce073859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('rte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6ecfd46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtepair = nltk.corpus.rte.pairs(['rte3_dev.xml'])[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cfbab230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on RTEPair in module nltk.corpus.reader.rte object:\n",
      "\n",
      "class RTEPair(builtins.object)\n",
      " |  RTEPair(pair, challenge=None, id=None, text=None, hyp=None, value=None, task=None, length=None)\n",
      " |  \n",
      " |  Container for RTE text-hypothesis pairs.\n",
      " |  \n",
      " |  The entailment relation is signalled by the ``value`` attribute in RTE1, and by\n",
      " |  ``entailment`` in RTE2 and RTE3. These both get mapped on to the ``entailment``\n",
      " |  attribute of this class.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, pair, challenge=None, id=None, text=None, hyp=None, value=None, task=None, length=None)\n",
      " |      :param challenge: version of the RTE challenge (i.e., RTE1, RTE2 or RTE3)\n",
      " |      :param id: identifier for the pair\n",
      " |      :param text: the text component of the pair\n",
      " |      :param hyp: the hypothesis component of the pair\n",
      " |      :param value: classification label for the pair\n",
      " |      :param task: attribute for the particular NLP task that the data was drawn from\n",
      " |      :param length: attribute for the length of the text of the pair\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(rtepair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "83adb317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'China is a member of SCO.'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtepair.hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8dc7f415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Parviz Davudi was representing Iran at a meeting of the Shanghai Co-operation Organisation (SCO), the fledgling association that binds Russia, China and four former Soviet republics of central Asia together to fight terrorism.'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtepair.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c99f18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = nltk.RTEFeatureExtractor(rtepair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "441977c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Co', 'four', 'Russia', 'Organisation', 'republics', 'former', 'Shanghai', 'Parviz', 'that', 'Iran', 'central', 'was', 'meeting', 'operation', 'binds', 'SCO', 'Asia', 'together', 'China', 'association', 'Soviet', 'fight', 'at', 'Davudi', 'representing', 'fledgling', 'terrorism.'}\n"
     ]
    }
   ],
   "source": [
    "print(extractor.text_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fa80c67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member', 'SCO.', 'China'}\n"
     ]
    }
   ],
   "source": [
    "print(extractor.hyp_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "82855827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(extractor.overlap('word'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b143f303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'China'}\n"
     ]
    }
   ],
   "source": [
    "print(extractor.overlap('ne'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "71d9b073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member'}\n"
     ]
    }
   ],
   "source": [
    "print(extractor.hyp_extra('word'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caf0af3",
   "metadata": {},
   "source": [
    "These features indicate that all important words in the hypothesis are contained in the text, and thus there is some evidence for labeling this as *True*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69084efe",
   "metadata": {},
   "source": [
    "## 2.4   Scaling Up to Large Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036038d8",
   "metadata": {},
   "source": [
    "Python provides an excellent environment for performing basic text processing and feature extraction. However, it is not able to perform the numerically intensive calculations required by machine learning methods nearly as quickly as lower-level languages such as C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2235dca3",
   "metadata": {},
   "source": [
    "If you plan to train classifiers with large amounts of training data or a large number of features, we recommend that you explore NLTK's facilities for interfacing with external machine learning packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8995249",
   "metadata": {},
   "source": [
    "# 3.   Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5eda23",
   "metadata": {},
   "source": [
    "The result of this evaluation is important for deciding **how trustworthy the model is**, and **for what purposes we can use it**.\n",
    "\n",
    "Evaluation can also be an effective tool for guiding us in **making future improvements to the model**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ace303b",
   "metadata": {},
   "source": [
    "## 3.1   The Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f703b23a",
   "metadata": {},
   "source": [
    "It is very important that the test set be distinct from the training corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a86d3e4",
   "metadata": {},
   "source": [
    "When building the test set, there is often a trade-off between the amount of data available for testing and the amount available for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd38f600",
   "metadata": {},
   "source": [
    "For classification tasks that have a small number of well-balanced labels and a diverse test set, a meaningful evaluation can be performed with as few as 100 evaluation instances. \n",
    "\n",
    "But if a classification task has a large number of labels, or includes very infrequent labels, then the size of the test set should be chosen to ensure that the least frequent label occurs at least 50 times. \n",
    "\n",
    "Additionally, if the test set contains many closely related instances — such as instances drawn from a single document — then the size of the test set should be increased to ensure that this lack of diversity does not skew the evaluation results. \n",
    "\n",
    "When large amounts of annotated data are available, **it is common to err on the side of safety by using 10% of the overall data for evaluation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03fbe49",
   "metadata": {},
   "source": [
    "下面以POS tagging任务为例说明：**当有大量标注数据可用时，使用10%的整体数据进行模型评估，可能会在安全方面犯错**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5571ae",
   "metadata": {},
   "source": [
    "从同一体裁（如news）中选择10%作为测试集，会使得开发集和测试机的样例非常相似，进而影响模型的评估结果（无法根据测试结果准确评估模型的泛化性能），如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a88340e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk.corpus import brown\n",
    "tagged_sents = list(brown.tagged_sents(categories='news'))\n",
    "random.shuffle(tagged_sents)\n",
    "size = int(len(tagged_sents) * 0.1)\n",
    "train_set, test_set = tagged_sents[size:], tagged_sents[:size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393a177",
   "metadata": {},
   "source": [
    "上面代码中使用了`random.shuffle`方法，会使得测试集和训练集使用来自相同文档的句子，进一步加剧了测试集和训练集的相似性，进而影响模型的评估结果（无法根据测试结果准确评估模型的泛化性能）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6996e61",
   "metadata": {},
   "source": [
    "对于同一体裁的标注语料，可以选择让训练数据和测试数据分别来自不同的文档，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c2935087",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ids = brown.fileids(categories='news')\n",
    "size = int(len(file_ids) * 0.1)\n",
    "train_set = brown.tagged_sents(file_ids[size:])\n",
    "test_set = brown.tagged_sents(file_ids[:size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d32b9c6",
   "metadata": {},
   "source": [
    "如果想要进行更严格的评估，可以让训练集和测试集使用不同体裁的文档，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "86344b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = brown.tagged_sents(categories='news')\n",
    "test_set = brown.tagged_sents(categories='fiction')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a8c548",
   "metadata": {},
   "source": [
    "如果使用上面的数据集划分构建了一个在测试集上表现良好的分类器，那么可以确信它具有较强的泛化能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b38b596",
   "metadata": {},
   "source": [
    "## 3.2   Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41265f06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
