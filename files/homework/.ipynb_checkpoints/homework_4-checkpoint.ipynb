{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3605d12b-1e46-4ff2-9f4b-017e8df78571",
   "metadata": {},
   "source": [
    "<center><font size=5 ><strong>Homework 4</strong></font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a1033-402d-4738-8ce6-9a03bd25edca",
   "metadata": {},
   "source": [
    "### **1. 题目说明**\n",
    "\n",
    "下表左侧有18个词性序列模式（POS Sequence patterns），右侧是每个模式在文本中对应的实例，`Freq.`列内容可忽略。例如，模式1`Noun Noun`对应的一个实例为`Group conversation`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6075d802-28da-4626-bd91-e23c91a77b18",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img width=\"850\" height=\"350\" src=\"https://github.com/zhangjianzhang/text_mining/blob/master/files/codes/lecture_7/patterns.jpg?raw=true\">\n",
    "<br>\n",
    "<center><em><strong>POS sequence patterns and instances</strong></em></center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56a83e-1782-4336-bddc-4f9d8a1f80a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **2. 题目要求**\n",
    "\n",
    "对给定的一个文本集合`text.csv`，从中抽取出符合上图中18个pattern的全部实例。\n",
    "\n",
    "例如，给定输入文本 ***you can send beautiful pictures anywhere.*** ，其中`beautiful pictures`符合pattern 3`Adjective Noun`，`send beautiful pictures`符合pattern 9`Verb Adjective Noun`\n",
    "\n",
    "<font style=\"color:#FF0000\">**注意**</font>：将全部匹配结果输出为一个字典，可以将该字典写入本地`json`文件，格式如下：\n",
    "```python\n",
    "{\n",
    "    '3':['beautiful picture']\n",
    "    '9':['send beautiful picture']\n",
    "}\n",
    "```\n",
    "key表示上图中pattern的编号，value为实例列表，列表中的实例需要是**小写**且**词形还原**的形式（lowercase lemma）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9ed0b1-f1db-4c88-a62d-078ebef7ce7b",
   "metadata": {},
   "source": [
    "### **3. 提示**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be8c05d-5bf5-4d3f-8049-77a3e5eeda16",
   "metadata": {},
   "source": [
    "- 分句，分词，词性标注，小写化，词形还原（lemmatization），词性序列匹配，抽取实例并保存；\n",
    "\n",
    "- 上述文本处理操作均可借助NLTK完成，当然，你也可以借助其他文本处理包（如 spacy, stanza等）实现上述文本处理步骤；\n",
    "\n",
    "- 可以参考课件、课程配套代码、互联网搜索资料。\n",
    "\n",
    "- nltk默认词性标注器使用的词性标签的含义：\n",
    "\n",
    "   - https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "   - 或者执行代码`nltk.help.upenn_tagset()`来查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51030df-d495-47b5-909d-1ebbf6cc00db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 请直接在该jupyter文件中写你的答案，并在截止日之前提高该jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1871c63a-9260-4190-b6c4-378791a0e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的包\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# lemmatization\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# 将词性标签映射为WordNet lemmatizer接受的词性标签\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de1514c9-5765-49ac-adc7-89a86f00889c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************1***************\n",
      "you can send beautiful pictures anywhere.\n",
      "[('you', 'PRP'), ('can', 'MD'), ('send', 'VB'), ('beautiful', 'JJ'), ('picture', 'NNS'), ('anywhere', 'RB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# 输入文本\n",
    "text = \"you can send beautiful pictures anywhere.\"\n",
    "# sentence segmentation (句子分割)\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "for idx,sent in enumerate(sentences):\n",
    "    print('*'*15 + str(idx+1) +'*'*15)\n",
    "    print(sent)\n",
    "    # 分词，词性标注，词形还原和小写化 (word tokenization, POS tagging, lemmatization and lowercase)\n",
    "    print([(wnl.lemmatize(w,get_wordnet_pos(t)).lower(),t) for w,t in nltk.pos_tag(nltk.word_tokenize(sent))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f15037-0c6b-4042-8a95-1bfc67558542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是一个长文本的预处理例子\n",
    "# text = \"THANK YOU so much for making this app such an enjoyable platform to connect with people all over the world. It has truly changed my life, and I could not be more satisfied with TikTok. I can’t wait to see what the future holds for TikTok, and for me on TikTok! I only went four stars because my only complaint is the community guideline violations process. I post strictly sports and often often get reported for violations, when they are not. My account is now in danger of being restricted. I go out of my way to ensure my content is safe for all. Thanks again, Kyle Carberry #verifykingkyle #verifykylecarberry\"\n",
    "# sentences = nltk.sent_tokenize(text)\n",
    "# for idx,sent in enumerate(sentences):\n",
    "#     print('*'*15 + str(idx+1) +'*'*15)\n",
    "#     print(sent)\n",
    "#     print([(wnl.lemmatize(w,get_wordnet_pos(t)).lower(),t) for w,t in nltk.pos_tag(nltk.word_tokenize(sent))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e2ceee-575e-4118-9e25-9b6b8178fad5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
