{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3605d12b-1e46-4ff2-9f4b-017e8df78571",
   "metadata": {},
   "source": [
    "<center><font size=5 ><strong>Homework 4</strong></font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a1033-402d-4738-8ce6-9a03bd25edca",
   "metadata": {},
   "source": [
    "### **1. 题目说明**\n",
    "\n",
    "下表左侧有18个词性序列模式（POS Sequence patterns），右侧是每个模式在文本中对应的实例，`Freq.`列内容可忽略。例如，模式1`Noun Noun`对应的一个实例为`Group conversation`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6075d802-28da-4626-bd91-e23c91a77b18",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img width=\"850\" height=\"350\" src=\"https://github.com/zhangjianzhang/text_mining/blob/master/files/codes/lecture_7/patterns.jpg?raw=true\">\n",
    "<br>\n",
    "<center><em><strong>POS sequence patterns and instances</strong></em></center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56a83e-1782-4336-bddc-4f9d8a1f80a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **2. 题目要求**\n",
    "\n",
    "对给定的一个文本集合`text.csv`，下载地址如下：\n",
    "\n",
    "https://raw.githubusercontent.com/zhangjianzhang/text_mining/master/files/homework/text.csv\n",
    "\n",
    "从中抽取出符合上图中18个pattern的全部实例。\n",
    "\n",
    "例如，给定输入文本 ***you can send beautiful pictures anywhere.*** ，其中`beautiful pictures`符合pattern 3`Adjective Noun`，`send beautiful pictures`符合pattern 9`Verb Adjective Noun`\n",
    "\n",
    "<font style=\"color:#FF0000\">**注意**</font>：将全部匹配结果输出为一个字典，可以将该字典写入本地`json`文件，格式如下：\n",
    "```python\n",
    "{\n",
    "    '3':['beautiful picture']\n",
    "    '9':['send beautiful picture']\n",
    "}\n",
    "```\n",
    "key表示上图中pattern的编号，value为实例列表，列表中的实例需要是**小写**且**词形还原**的形式（lowercase lemma）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9ed0b1-f1db-4c88-a62d-078ebef7ce7b",
   "metadata": {},
   "source": [
    "### **3. 提示**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be8c05d-5bf5-4d3f-8049-77a3e5eeda16",
   "metadata": {},
   "source": [
    "- 分句，分词，词性标注，小写化，词形还原（lemmatization），词性序列匹配，抽取实例并保存；\n",
    "\n",
    "- 上述文本处理操作均可借助NLTK完成，当然，你也可以借助其他文本处理包（如 spacy, stanza等）实现上述文本处理步骤；\n",
    "\n",
    "- 可以参考课件、课程配套代码、互联网搜索资料。\n",
    "\n",
    "- nltk默认词性标注器使用的词性标签的含义：\n",
    "\n",
    "   - https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "   - 或者执行代码`nltk.help.upenn_tagset()`来查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e51030df-d495-47b5-909d-1ebbf6cc00db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 请直接在该jupyter文件中写你的答案，并在截止日之前提高该jupyter\n",
    "\n",
    "# Please write your codes below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee0f87bb-2691-4e8d-9242-a8655de5c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的包\n",
    "# fileUtils包是我自己写的文件读写模块，可以从课程网站下载\n",
    "# 将解压后得到的utils文件夹，放到目录 anaconda3/lib/python3.9/ 中即可\n",
    "import nltk\n",
    "from utils.fileUtils import *\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# lemmatization\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# 将词性标签映射为WordNet lemmatizer接受的词性标签\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4400a9ca-3cd8-473e-85b9-1408ea629755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成N-gram\n",
    "def get_n_gram(text_list,n):\n",
    "    grams = []\n",
    "    m = len(text_list) - n + 1\n",
    "    for idx in range(m):\n",
    "        gram = text_list[idx:idx+n]\n",
    "        grams.append(gram)\n",
    "    return grams\n",
    "# sample_text = 'so much for making this app such an enjoyable'.split()\n",
    "# get_n_gram(sample_text,1)\n",
    "# get_n_gram(sample_text,2)\n",
    "# get_n_gram(sample_text,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f88cb3-8666-41c8-b8a2-b8beeb93657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为便于匹配，将pattern中的词性标签进行映射\n",
    "def pos_tag_map(pos_tag):\n",
    "    # 名词\n",
    "    if pos_tag.startswith('N'):\n",
    "        return 'N'\n",
    "    # 动词\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return 'V'\n",
    "    # 形容词\n",
    "    elif pos_tag.startswith('J'):\n",
    "        return 'J'\n",
    "    # 代词\n",
    "    elif pos_tag in ['PRP','PRP$','WP','WP$']:\n",
    "        return 'P'\n",
    "    # 连词 CC，介词IN\n",
    "    else:\n",
    "        return pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e203027-0457-4d54-aa67-50e124539dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词，词性标注，词形还原和小写化 (word tokenization, POS tagging, lemmatization and lowercase)\n",
    "def text_processing(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    sent_lists = []\n",
    "    for idx,sent in enumerate(sentences):\n",
    "        sent_list = [(wnl.lemmatize(w,get_wordnet_pos(t)).lower(),pos_tag_map(t)) for w,t in nltk.pos_tag(nltk.word_tokenize(sent))]\n",
    "        sent_lists.append(sent_list)\n",
    "    return sent_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ebee68f-2c26-4a81-b47c-5c346e7916e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义pattern\n",
    "patterns = [['N','N'],\n",
    "           ['V','N'],\n",
    "           ['J','N'],\n",
    "           ['N','CC','N'],\n",
    "           ['J','N','N'],\n",
    "           ['N','N','N'],\n",
    "           ['V','P','N'],\n",
    "           ['V','N','N'],\n",
    "           ['V','J','N'],\n",
    "           ['J','J','N'],\n",
    "           ['N','IN','N'],\n",
    "           ['V','DT','N'],\n",
    "           ['V','N','IN','N'],\n",
    "           ['J','N','N','N'],\n",
    "           ['J','CC','J'],\n",
    "           ['V','IN','J','N'],\n",
    "            ['V','P','J','N'],\n",
    "           ['N','CC','N','N']]\n",
    "\n",
    "patterns_dict = {k+1:v for k,v in enumerate(patterns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ad8291f-23e4-4de5-8ec5-91a99ead5338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义结果字典\n",
    "result_dict = {k+1:set() for k in range(len(patterns))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c450238-0e02-4717-b668-80a2b35e6f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取待处理数据\n",
    "lines = readCsvToList('./text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1a8f4a1-41eb-4165-abbe-7b32e7e0192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模式匹配，将匹配到的实例存入result_dict\n",
    "for line in lines:\n",
    "    tokenized_sents = text_processing(line[0])\n",
    "    for tokenized_sent in tokenized_sents:\n",
    "        gram_2 = get_n_gram(tokenized_sent, 2)\n",
    "        gram_3 = get_n_gram(tokenized_sent, 3)\n",
    "        gram_4 = get_n_gram(tokenized_sent, 4)\n",
    "        for item in gram_2 + gram_3 + gram_4:\n",
    "            pos_list = []\n",
    "            word_list = []\n",
    "            for word_tuple in item:\n",
    "                word, pos = word_tuple\n",
    "                pos_list.append(pos)\n",
    "                word_list.append(word)\n",
    "            for k,pattern in patterns_dict.items():\n",
    "                if pos_list == pattern:\n",
    "                    result_dict[k].add(' '.join(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a831e06f-7c31-4223-99a4-b58703f29cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将result_dict保存到本地json文件中\n",
    "dumpJson('./pattern_match_result.json', {k:list(v) for k,v in result_dict.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e54f1-0914-40ec-bc1f-34f7bae6e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对上述匹配结果还可以进行进一步改进，比如：\n",
    "# 1. 使用更准确的词性标注器，spacy\n",
    "# 2. 取出匹配结果中的噪音\n",
    "# 3. 对于嵌套的模式进行去重"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
